{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02.5 - Master Races Verification\n",
        "\n",
        "This notebook performs comprehensive completeness and quality verification on the combined `master_races.csv` dataset.\n",
        "\n",
        "**Purpose**: Verify that the data combining process created a complete and correct master dataset.\n",
        "\n",
        "**What this notebook checks:**\n",
        "1. **Basic Structure**: Rows, columns, data types\n",
        "2. **Uniqueness**: One row per (raceId, driverId) combination\n",
        "3. **Temporal Coverage**: Year and race coverage (1994-2024)\n",
        "4. **Merge Success Rates**: How well each data source merged\n",
        "5. **Completeness**: Missing values by column and source\n",
        "6. **Data Quality**: Value ranges, relationships, consistency\n",
        "7. **Target Variable**: Podium distribution and patterns\n",
        "\n",
        "**When to use**: After running `02_data_combining.ipynb` to verify the combined dataset is ready for EDA and modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data: C:\\Users\\erikv\\Downloads\\F1\\data\\processed\n",
            "Kaggle data (for reference): C:\\Users\\erikv\\Downloads\\F1\\data\\raw\\kaggle\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up paths\n",
        "PROJECT_ROOT = Path(r\"C:\\Users\\erikv\\Downloads\\F1\")\n",
        "PROCESSED_ROOT = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "KAGGLE_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / \"kaggle\"\n",
        "\n",
        "print(f\"Processed data: {PROCESSED_ROOT}\")\n",
        "print(f\"Kaggle data (for reference): {KAGGLE_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Master Races Dataset\n",
        "\n",
        "Load the combined master_races.csv file and display basic information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Master Races Dataset Loaded\n",
            "============================================================\n",
            "Shape: 12,358 rows × 82 columns\n",
            "Date range: 1994-03-27 00:00:00 to 2024-12-08 00:00:00\n",
            "Years: 1994 - 2024\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>resultId</th>\n",
              "      <th>raceId</th>\n",
              "      <th>driverId</th>\n",
              "      <th>constructorId</th>\n",
              "      <th>number</th>\n",
              "      <th>grid</th>\n",
              "      <th>position</th>\n",
              "      <th>positionText</th>\n",
              "      <th>positionOrder</th>\n",
              "      <th>points</th>\n",
              "      <th>...</th>\n",
              "      <th>sprint_results_time</th>\n",
              "      <th>sprint_results_milliseconds</th>\n",
              "      <th>sprint_results_fastestLap</th>\n",
              "      <th>sprint_results_fastestLapTime</th>\n",
              "      <th>sprint_results_statusId</th>\n",
              "      <th>lap_time_variance</th>\n",
              "      <th>throttle_variance</th>\n",
              "      <th>overtake_attempts</th>\n",
              "      <th>avg_pit_stops</th>\n",
              "      <th>podium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   resultId  raceId  driverId  constructorId  number  grid position  \\\n",
              "0         1      18         1              1      22     1        1   \n",
              "1         2      18         2              2       3     5        2   \n",
              "2         3      18         3              3       7     7        3   \n",
              "\n",
              "  positionText  positionOrder  points  ...  sprint_results_time  \\\n",
              "0            1              1    10.0  ...                  NaN   \n",
              "1            2              2     8.0  ...                  NaN   \n",
              "2            3              3     6.0  ...                  NaN   \n",
              "\n",
              "  sprint_results_milliseconds sprint_results_fastestLap  \\\n",
              "0                         NaN                       NaN   \n",
              "1                         NaN                       NaN   \n",
              "2                         NaN                       NaN   \n",
              "\n",
              "  sprint_results_fastestLapTime sprint_results_statusId lap_time_variance  \\\n",
              "0                           NaN                     NaN               NaN   \n",
              "1                           NaN                     NaN               NaN   \n",
              "2                           NaN                     NaN               NaN   \n",
              "\n",
              "  throttle_variance  overtake_attempts  avg_pit_stops  podium  \n",
              "0               NaN                NaN            NaN       1  \n",
              "1               NaN                NaN            NaN       1  \n",
              "2               NaN                NaN            NaN       1  \n",
              "\n",
              "[3 rows x 82 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load master_races.csv\n",
        "master_path = PROCESSED_ROOT / \"master_races.csv\"\n",
        "\n",
        "if not master_path.exists():\n",
        "    raise FileNotFoundError(f\"master_races.csv not found at {master_path}. Run 02_data_combining.ipynb first.\")\n",
        "\n",
        "master = pd.read_csv(master_path, low_memory=False)\n",
        "\n",
        "# Convert date to datetime\n",
        "if 'date' in master.columns:\n",
        "    master['date'] = pd.to_datetime(master['date'], errors='coerce')\n",
        "\n",
        "print(f\"Master Races Dataset Loaded\")\n",
        "print(f\"=\" * 60)\n",
        "print(f\"Shape: {master.shape[0]:,} rows × {master.shape[1]} columns\")\n",
        "print(f\"Date range: {master['date'].min()} to {master['date'].max()}\")\n",
        "print(f\"Years: {master['year'].min()} - {master['year'].max()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "master.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "- **Rows**: Should be ~12,000-13,000 (one per raceId+driverId for 1994+)\n",
        "- **Columns**: Should be ~80-82 (combined from all sources)\n",
        "- **Date range**: 1994-03-27 to 2024-12-08 (or latest race date)\n",
        "- **Years**: 1994 - 2024\n",
        "\n",
        "**What to look for:**\n",
        "- ✅ **Good signs**: \n",
        "  - Expected number of rows (~12K)\n",
        "  - Date range starts from 1994\n",
        "  - All expected columns present\n",
        "- ⚠️ **Warning signs**: \n",
        "  - Much fewer rows than expected (missing data)\n",
        "  - Date range doesn't start in 1994 (filter didn't work)\n",
        "  - Missing expected columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Uniqueness Verification\n",
        "\n",
        "Verify that each (raceId, driverId) combination appears exactly once.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for duplicate (raceId, driverId) combinations\n",
        "duplicate_check = master.groupby(['raceId', 'driverId']).size()\n",
        "duplicates = duplicate_check[duplicate_check > 1]\n",
        "\n",
        "if len(duplicates) == 0:\n",
        "    print(\"✅ PASS: No duplicate (raceId, driverId) combinations found\")\n",
        "    print(f\"   Each driver-race combination appears exactly once.\")\n",
        "else:\n",
        "    print(f\"⚠️ WARNING: Found {len(duplicates)} duplicate (raceId, driverId) combinations:\")\n",
        "    print(duplicates.head(10))\n",
        "    print(f\"\\nFirst duplicate example:\")\n",
        "    example_race = duplicates.index[0][0]\n",
        "    example_driver = duplicates.index[0][1]\n",
        "    print(master[(master['raceId'] == example_race) & (master['driverId'] == example_driver)])\n",
        "\n",
        "print(f\"\\nTotal unique (raceId, driverId) combinations: {len(duplicate_check):,}\")\n",
        "print(f\"Total rows: {len(master):,}\")\n",
        "print(f\"Match: {len(duplicate_check) == len(master)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "- **No duplicates**: Each (raceId, driverId) should appear exactly once\n",
        "- **Match**: Number of unique combinations should equal total rows\n",
        "\n",
        "**What to look for:**\n",
        "- ✅ **Good signs**: No duplicates found, counts match\n",
        "- ⚠️ **Warning signs**: Duplicates indicate merge issues or data quality problems\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Temporal Coverage Analysis\n",
        "\n",
        "Check year and race coverage to ensure complete temporal data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Year coverage\n",
        "year_coverage = master.groupby('year').agg({\n",
        "    'raceId': 'nunique',\n",
        "    'driverId': 'nunique',\n",
        "    'resultId': 'count'\n",
        "}).rename(columns={\n",
        "    'raceId': 'unique_races',\n",
        "    'driverId': 'unique_drivers',\n",
        "    'resultId': 'total_results'\n",
        "})\n",
        "\n",
        "print(\"Year Coverage Analysis:\")\n",
        "print(\"=\" * 60)\n",
        "print(year_coverage)\n",
        "\n",
        "# Check for missing years in 1994-2024 range\n",
        "expected_years = set(range(1994, 2025))\n",
        "actual_years = set(master['year'].unique())\n",
        "missing_years = expected_years - actual_years\n",
        "\n",
        "if missing_years:\n",
        "    print(f\"\\n⚠️ WARNING: Missing years: {sorted(missing_years)}\")\n",
        "else:\n",
        "    print(f\"\\n✅ All expected years present (1994-2024)\")\n",
        "\n",
        "# Race coverage per year\n",
        "print(f\"\\nRace Coverage Summary:\")\n",
        "print(f\"  Average races per year: {year_coverage['unique_races'].mean():.1f}\")\n",
        "print(f\"  Min races in a year: {year_coverage['unique_races'].min()}\")\n",
        "print(f\"  Max races in a year: {year_coverage['unique_races'].max()}\")\n",
        "print(f\"  Typical F1 season has 20-24 races\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Merge Success Rates\n",
        "\n",
        "Check how successfully each data source merged with the base results table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define key indicator columns for each merged source\n",
        "merge_indicators = {\n",
        "    'results': ['resultId'],  # Base table - should be 100%\n",
        "    'races': ['year', 'date'],  # Should be 100% (used for filtering)\n",
        "    'circuits': ['circuit_name', 'country'],\n",
        "    'drivers': ['forename', 'surname'],\n",
        "    'constructors': ['name_constructor'],\n",
        "    'driver_standings': ['driverStandingsId', 'driver_standings_points'],\n",
        "    'constructor_standings': ['constructorStandingsId', 'constructor_standings_points'],\n",
        "    'constructor_results': ['constructorResultsId', 'constructor_results_points'],\n",
        "    'qualifying': ['qualifyId', 'q1'],\n",
        "    'sprint_results': ['sprint_results_resultId']\n",
        "}\n",
        "\n",
        "print(\"Merge Success Rates:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "merge_stats = []\n",
        "for source, indicator_cols in merge_indicators.items():\n",
        "    # Check if at least one indicator column exists and has data\n",
        "    found_cols = [col for col in indicator_cols if col in master.columns]\n",
        "    \n",
        "    if not found_cols:\n",
        "        coverage_pct = 0.0\n",
        "        status = \"❌ NOT MERGED\"\n",
        "    else:\n",
        "        # Use the first found column for coverage calculation\n",
        "        coverage_col = found_cols[0]\n",
        "        coverage_count = master[coverage_col].notna().sum()\n",
        "        coverage_pct = (coverage_count / len(master)) * 100\n",
        "        status = \"✅\" if coverage_pct > 95 else \"⚠️\" if coverage_pct > 50 else \"❌\"\n",
        "    \n",
        "    merge_stats.append({\n",
        "        'source': source,\n",
        "        'coverage_pct': coverage_pct,\n",
        "        'coverage_count': coverage_count if found_cols else 0,\n",
        "        'status': status\n",
        "    })\n",
        "    \n",
        "    print(f\"{status} {source:25s}: {coverage_pct:6.2f}% ({coverage_count:,}/{len(master):,} rows)\")\n",
        "\n",
        "# Summary\n",
        "merge_df = pd.DataFrame(merge_stats)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Fully merged (>95%): {(merge_df['coverage_pct'] > 95).sum()} sources\")\n",
        "print(f\"  Partially merged (50-95%): {((merge_df['coverage_pct'] >= 50) & (merge_df['coverage_pct'] <= 95)).sum()} sources\")\n",
        "print(f\"  Poorly merged (<50%): {(merge_df['coverage_pct'] < 50).sum()} sources\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Missing Values Analysis\n",
        "\n",
        "Analyze missing values by column and data source to identify data gaps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate missing values\n",
        "missing_stats = []\n",
        "for col in master.columns:\n",
        "    missing_count = master[col].isnull().sum()\n",
        "    missing_pct = (missing_count / len(master)) * 100\n",
        "    missing_stats.append({\n",
        "        'column': col,\n",
        "        'missing_count': missing_count,\n",
        "        'missing_pct': missing_pct,\n",
        "        'dtype': str(master[col].dtype)\n",
        "    })\n",
        "\n",
        "missing_df = pd.DataFrame(missing_stats).sort_values('missing_pct', ascending=False)\n",
        "\n",
        "# Group by expected missing patterns\n",
        "print(\"Missing Values Analysis:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Placeholder columns (expected to be 100% missing)\n",
        "placeholder_cols = ['lap_time_variance', 'throttle_variance', 'overtake_attempts', 'avg_pit_stops']\n",
        "print(f\"\\n1. Placeholder Features (expected 100% missing):\")\n",
        "placeholder_missing = missing_df[missing_df['column'].isin(placeholder_cols)]\n",
        "print(placeholder_missing[['column', 'missing_pct']].to_string(index=False))\n",
        "\n",
        "# Sprint results (expected high missing - only recent seasons)\n",
        "sprint_cols = [col for col in master.columns if col.startswith('sprint_results_')]\n",
        "print(f\"\\n2. Sprint Results (expected ~97% missing - only 2021+):\")\n",
        "sprint_missing = missing_df[missing_df['column'].isin(sprint_cols)].head(5)\n",
        "print(sprint_missing[['column', 'missing_pct']].to_string(index=False))\n",
        "\n",
        "# Other high missing columns\n",
        "print(f\"\\n3. Other Columns with Missing Values (>5%):\")\n",
        "other_missing = missing_df[\n",
        "    (~missing_df['column'].isin(placeholder_cols + sprint_cols)) & \n",
        "    (missing_df['missing_pct'] > 5)\n",
        "]\n",
        "if len(other_missing) > 0:\n",
        "    print(other_missing[['column', 'missing_pct']].to_string(index=False))\n",
        "else:\n",
        "    print(\"  None - all non-placeholder columns have <5% missing\")\n",
        "\n",
        "# Critical columns (should have minimal missing)\n",
        "critical_cols = ['raceId', 'driverId', 'year', 'date', 'positionOrder', 'points', 'circuit_name', 'forename', 'surname']\n",
        "print(f\"\\n4. Critical Columns Missing Check:\")\n",
        "critical_missing = missing_df[missing_df['column'].isin(critical_cols)]\n",
        "for _, row in critical_missing.iterrows():\n",
        "    status = \"✅\" if row['missing_pct'] == 0 else \"⚠️\" if row['missing_pct'] < 1 else \"❌\"\n",
        "    print(f\"  {status} {row['column']:25s}: {row['missing_pct']:6.2f}% missing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "- **Placeholder features**: 100% missing (expected - will be filled later)\n",
        "- **Sprint results**: ~97% missing (only 2021+ seasons have sprints)\n",
        "- **Qualifying (q2, q3)**: ~20-40% missing (not all drivers make it to Q2/Q3)\n",
        "- **Critical columns**: 0% missing (raceId, driverId, year, date, positionOrder, etc.)\n",
        "\n",
        "**What to look for:**\n",
        "- ✅ **Good signs**: \n",
        "  - Critical columns have 0% missing\n",
        "  - Expected patterns (sprints, placeholders)\n",
        "- ⚠️ **Warning signs**: \n",
        "  - Critical columns with missing values (data quality issue)\n",
        "  - Unexpected high missing rates in non-placeholder columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Quality Checks\n",
        "\n",
        "Verify value ranges, relationships, and consistency across columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Data Quality Checks:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Position validation\n",
        "print(\"\\n1. Position Validation:\")\n",
        "print(f\"  positionOrder range: {master['positionOrder'].min()} - {master['positionOrder'].max()}\")\n",
        "print(f\"  positionOrder > 20: {(master['positionOrder'] > 20).sum():,} rows ({((master['positionOrder'] > 20).sum() / len(master) * 100):.1f}%)\")\n",
        "print(f\"  positionOrder <= 0: {(master['positionOrder'] <= 0).sum():,} rows\")\n",
        "\n",
        "# Check if points match position (top 10 get points in most eras)\n",
        "top_positions = master[master['positionOrder'] <= 10]\n",
        "points_in_top10 = (top_positions['points'] > 0).sum()\n",
        "print(f\"  Rows with positionOrder <= 10 and points > 0: {points_in_top10:,}/{len(top_positions):,} ({points_in_top10/len(top_positions)*100:.1f}%)\")\n",
        "\n",
        "# 2. Date consistency\n",
        "print(\"\\n2. Date Consistency:\")\n",
        "print(f\"  Invalid dates: {master['date'].isnull().sum()} rows\")\n",
        "print(f\"  Dates outside 1994-2024: {((master['date'] < '1994-01-01') | (master['date'] > '2024-12-31')).sum()} rows\")\n",
        "\n",
        "# 3. Year consistency\n",
        "print(\"\\n3. Year Consistency:\")\n",
        "print(f\"  Years < 1994: {(master['year'] < 1994).sum()} rows\")\n",
        "print(f\"  Years > 2024: {(master['year'] > 2024).sum()} rows\")\n",
        "year_date_match = (master['date'].dt.year == master['year']).sum()\n",
        "print(f\"  Year matches date year: {year_date_match:,}/{len(master):,} ({year_date_match/len(master)*100:.1f}%)\")\n",
        "\n",
        "# 4. Driver-Constructor relationship\n",
        "print(\"\\n4. Driver-Constructor Consistency:\")\n",
        "print(f\"  Unique drivers: {master['driverId'].nunique():,}\")\n",
        "print(f\"  Unique constructors: {master['constructorId'].nunique():,}\")\n",
        "print(f\"  Unique (driverId, constructorId) pairs: {master[['driverId', 'constructorId']].drop_duplicates().shape[0]:,}\")\n",
        "\n",
        "# 5. Podium target variable\n",
        "print(\"\\n5. Target Variable (Podium) Validation:\")\n",
        "if 'podium' in master.columns:\n",
        "    podium_dist = master['podium'].value_counts()\n",
        "    podium_rate = master['podium'].mean()\n",
        "    print(f\"  Podium (1): {podium_dist.get(1, 0):,} rows ({podium_rate*100:.2f}%)\")\n",
        "    print(f\"  Non-podium (0): {podium_dist.get(0, 0):,} rows ({(1-podium_rate)*100:.2f}%)\")\n",
        "    print(f\"  Expected podium rate: ~14-15% (3 podiums per ~20 drivers)\")\n",
        "    \n",
        "    # Check if podium matches positionOrder\n",
        "    podium_matches = (master['podium'] == (master['positionOrder'] <= 3).astype(int)).sum()\n",
        "    print(f\"  Podium matches positionOrder <= 3: {podium_matches:,}/{len(master):,} ({podium_matches/len(master)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "- **positionOrder**: Range from 1 to ~22-24 (max grid positions)\n",
        "- **Points**: Most positions <= 10 should have points > 0\n",
        "- **Dates**: All valid, within 1994-2024 range\n",
        "- **Year consistency**: Year should match date.year\n",
        "- **Podium rate**: ~14-15% (3 podiums per ~20 drivers per race)\n",
        "- **Podium definition**: Should match positionOrder <= 3\n",
        "\n",
        "**What to look for:**\n",
        "- ✅ **Good signs**: \n",
        "  - Reasonable position ranges\n",
        "  - Dates are valid and consistent\n",
        "  - Podium rate around 14-15%\n",
        "  - Podium matches positionOrder definition\n",
        "- ⚠️ **Warning signs**: \n",
        "  - Invalid positions (< 1 or unreasonably high)\n",
        "  - Invalid dates or year mismatches\n",
        "  - Podium rate far from expected (~14-15%)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Coverage by Data Source (Detailed)\n",
        "\n",
        "Check coverage for each merged source in more detail, especially for time-sensitive data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check qualifying coverage by year\n",
        "if 'qualifyId' in master.columns:\n",
        "    print(\"Qualifying Coverage by Year:\")\n",
        "    print(\"=\" * 60)\n",
        "    qualifying_by_year = master.groupby('year').agg({\n",
        "        'qualifyId': lambda x: x.notna().sum(),\n",
        "        'resultId': 'count'\n",
        "    })\n",
        "    qualifying_by_year['coverage_pct'] = (qualifying_by_year['qualifyId'] / qualifying_by_year['resultId'] * 100)\n",
        "    qualifying_by_year.columns = ['with_qualifying', 'total_results', 'coverage_pct']\n",
        "    print(qualifying_by_year)\n",
        "\n",
        "# Check sprint results coverage by year (should only be 2021+)\n",
        "if 'sprint_results_resultId' in master.columns:\n",
        "    print(\"\\n\\nSprint Results Coverage by Year:\")\n",
        "    print(\"=\" * 60)\n",
        "    sprint_by_year = master.groupby('year').agg({\n",
        "        'sprint_results_resultId': lambda x: x.notna().sum(),\n",
        "        'resultId': 'count'\n",
        "    })\n",
        "    sprint_by_year['coverage_pct'] = (sprint_by_year['sprint_results_resultId'] / sprint_by_year['resultId'] * 100)\n",
        "    sprint_by_year.columns = ['with_sprint', 'total_results', 'coverage_pct']\n",
        "    # Only show years with some sprint data\n",
        "    sprint_by_year_filtered = sprint_by_year[sprint_by_year['with_sprint'] > 0]\n",
        "    print(sprint_by_year_filtered)\n",
        "\n",
        "# Check driver_standings coverage by year\n",
        "if 'driverStandingsId' in master.columns:\n",
        "    print(\"\\n\\nDriver Standings Coverage by Year:\")\n",
        "    print(\"=\" * 60)\n",
        "    standings_by_year = master.groupby('year').agg({\n",
        "        'driverStandingsId': lambda x: x.notna().sum(),\n",
        "        'resultId': 'count'\n",
        "    })\n",
        "    standings_by_year['coverage_pct'] = (standings_by_year['driverStandingsId'] / standings_by_year['resultId'] * 100)\n",
        "    standings_by_year.columns = ['with_standings', 'total_results', 'coverage_pct']\n",
        "    # Show years with low coverage\n",
        "    low_coverage = standings_by_year[standings_by_year['coverage_pct'] < 95]\n",
        "    if len(low_coverage) > 0:\n",
        "        print(\"Years with <95% coverage:\")\n",
        "        print(low_coverage)\n",
        "    else:\n",
        "        print(\"All years have >95% coverage\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "- **Qualifying**: Coverage should increase over time (better data in recent years), typically 85-95%\n",
        "- **Sprint Results**: Should only appear from 2021+ (sprints introduced in 2021), ~2-3% overall\n",
        "- **Driver Standings**: Should be >95% for all years (very high coverage)\n",
        "\n",
        "**What to look for:**\n",
        "- ✅ **Good signs**: \n",
        "  - Qualifying coverage consistent or improving over time\n",
        "  - Sprint results only in 2021+\n",
        "  - Standings consistently high\n",
        "- ⚠️ **Warning signs**: \n",
        "  - Sudden drops in qualifying coverage (data gap)\n",
        "  - Sprint results before 2021 (data quality issue)\n",
        "  - Low standings coverage in any year\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary Report\n",
        "\n",
        "Generate a comprehensive summary report of all findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive summary\n",
        "# Check which variables exist from previous cells\n",
        "duplicates_found = 0\n",
        "if 'duplicates' in locals():\n",
        "    duplicates_found = len(duplicates)\n",
        "\n",
        "if 'missing_years' not in locals():\n",
        "    expected_years = set(range(1994, 2025))\n",
        "    actual_years = set(master['year'].unique())\n",
        "    missing_years = sorted(list(expected_years - actual_years))\n",
        "else:\n",
        "    missing_years = sorted(missing_years) if missing_years else []\n",
        "\n",
        "if 'year_coverage' not in locals():\n",
        "    year_coverage = master.groupby('year').agg({'raceId': 'nunique'})\n",
        "    year_coverage.columns = ['unique_races']\n",
        "\n",
        "if 'merge_df' not in locals():\n",
        "    merge_df = pd.DataFrame()\n",
        "\n",
        "summary = {\n",
        "    'dataset': 'master_races.csv',\n",
        "    'verification_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'basic_stats': {\n",
        "        'total_rows': len(master),\n",
        "        'total_columns': len(master.columns),\n",
        "        'date_range_start': str(master['date'].min()),\n",
        "        'date_range_end': str(master['date'].max()),\n",
        "        'year_range': f\"{master['year'].min()}-{master['year'].max()}\"\n",
        "    },\n",
        "    'uniqueness': {\n",
        "        'unique_race_driver_pairs': len(master.groupby(['raceId', 'driverId'])),\n",
        "        'duplicates_found': duplicates_found,\n",
        "        'status': 'PASS' if duplicates_found == 0 else 'FAIL'\n",
        "    },\n",
        "    'temporal_coverage': {\n",
        "        'expected_years': list(range(1994, 2025)),\n",
        "        'actual_years': sorted(master['year'].unique().tolist()),\n",
        "        'missing_years': missing_years,\n",
        "        'avg_races_per_year': float(year_coverage['unique_races'].mean())\n",
        "    },\n",
        "    'merge_success_rates': merge_df.to_dict('records') if len(merge_df) > 0 else [],\n",
        "    'data_quality': {\n",
        "        'invalid_positions': int((master['positionOrder'] <= 0).sum()),\n",
        "        'invalid_dates': int(master['date'].isnull().sum()),\n",
        "        'year_date_mismatches': int((master['date'].dt.year != master['year']).sum()),\n",
        "        'podium_rate': float(master['podium'].mean()) if 'podium' in master.columns else None\n",
        "    }\n",
        "}\n",
        "\n",
        "# Print summary\n",
        "print(\"Master Races Verification Summary\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Dataset: {summary['dataset']}\")\n",
        "print(f\"Verification Date: {summary['verification_date']}\")\n",
        "print(f\"\\nBasic Statistics:\")\n",
        "print(f\"  Rows: {summary['basic_stats']['total_rows']:,}\")\n",
        "print(f\"  Columns: {summary['basic_stats']['total_columns']}\")\n",
        "print(f\"  Date Range: {summary['basic_stats']['date_range_start']} to {summary['basic_stats']['date_range_end']}\")\n",
        "print(f\"  Year Range: {summary['basic_stats']['year_range']}\")\n",
        "\n",
        "print(f\"\\nUniqueness Check:\")\n",
        "print(f\"  Unique (raceId, driverId) pairs: {summary['uniqueness']['unique_race_driver_pairs']:,}\")\n",
        "print(f\"  Duplicates found: {summary['uniqueness']['duplicates_found']}\")\n",
        "print(f\"  Status: {summary['uniqueness']['status']}\")\n",
        "\n",
        "print(f\"\\nTemporal Coverage:\")\n",
        "print(f\"  Missing years: {missing_years if missing_years else 'None'}\")\n",
        "print(f\"  Average races per year: {summary['temporal_coverage']['avg_races_per_year']:.1f}\")\n",
        "\n",
        "print(f\"\\nData Quality:\")\n",
        "print(f\"  Invalid positions: {summary['data_quality']['invalid_positions']}\")\n",
        "print(f\"  Invalid dates: {summary['data_quality']['invalid_dates']}\")\n",
        "print(f\"  Year-date mismatches: {summary['data_quality']['year_date_mismatches']}\")\n",
        "if summary['data_quality']['podium_rate']:\n",
        "    print(f\"  Podium rate: {summary['data_quality']['podium_rate']*100:.2f}%\")\n",
        "\n",
        "print(f\"\\n✅ Dataset is ready for EDA and modeling!\" if summary['uniqueness']['status'] == 'PASS' else \"\\n⚠️ Please review warnings above before proceeding.\")\n",
        "\n",
        "# Save summary to JSON\n",
        "import json\n",
        "summary_path = PROCESSED_ROOT / \"master_races_verification_report.json\"\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump(summary, f, indent=2, default=str)\n",
        "\n",
        "print(f\"\\nDetailed report saved to: {summary_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output:**\n",
        "- Summary of all verification checks\n",
        "- JSON report saved to `data/processed/master_races_verification_report.json`\n",
        "\n",
        "**What to look for:**\n",
        "- ✅ **Ready for next steps if**: \n",
        "  - No duplicates found\n",
        "  - All critical checks pass\n",
        "  - Merge success rates are acceptable\n",
        "- ⚠️ **Review needed if**: \n",
        "  - Duplicates found\n",
        "  - Critical columns missing\n",
        "  - Data quality issues detected\n",
        "\n",
        "**Next Steps:**\n",
        "- If verification passes → Proceed to `03_exploratory_data_analysis.ipynb`\n",
        "- If issues found → Review and fix in `02_data_combining.ipynb`, then re-run this verification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
