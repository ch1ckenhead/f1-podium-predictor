{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02.8 - Laps Data Exploration\n",
        "\n",
        "This notebook explores the LAPS data from FastF1, focusing on:\n",
        "- Understanding data structure and columns\n",
        "- Comparing datasets across years for consistency\n",
        "- Validating data completeness (events, sessions, drivers, coverage)\n",
        "- Identifying features for extraction\n",
        "- Checking year-over-year consistency in row counts, data quality, and coverage\n",
        "\n",
        "## Goals:\n",
        "- Understand the structure of LAPS data\n",
        "- Identify available columns and data types\n",
        "- Compare row counts across years\n",
        "- Validate data completeness and consistency\n",
        "- Prepare for feature extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastF1 data: C:\\Users\\erikv\\Downloads\\F1\\data\\raw\\fastf1_2018plus\n",
            "Python version: 3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]\n",
            "Pandas version: 2.3.3\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up paths\n",
        "PROJECT_ROOT = Path(r\"C:\\Users\\erikv\\Downloads\\F1\")\n",
        "FASTF1_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / \"fastf1_2018plus\"\n",
        "\n",
        "print(f\"FastF1 data: {FASTF1_ROOT}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. File Size Analysis\n",
        "Check the size of all LAPS files to understand data volume.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LAPS File Sizes:\n",
            "============================================================\n",
            "ALL_LAPS_2018.csv                   19.27 MB ( 0.019 GB)\n",
            "ALL_LAPS_2019.csv                   14.97 MB ( 0.015 GB)\n",
            "ALL_LAPS_2020.csv                   12.95 MB ( 0.013 GB)\n",
            "ALL_LAPS_2021.csv                   20.34 MB ( 0.020 GB)\n",
            "ALL_LAPS_2022.csv                   18.74 MB ( 0.018 GB)\n",
            "ALL_LAPS_2023.csv                   19.34 MB ( 0.019 GB)\n",
            "ALL_LAPS_2024.csv                   21.06 MB ( 0.021 GB)\n",
            "============================================================\n",
            "Total                              126.66 MB ( 0.124 GB)\n",
            "\n",
            "Number of files: 7\n"
          ]
        }
      ],
      "source": [
        "# Check file sizes for all laps files\n",
        "laps_files = sorted(FASTF1_ROOT.glob(\"ALL_LAPS_*.csv\"))\n",
        "\n",
        "print(\"LAPS File Sizes:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "total_size = 0\n",
        "file_sizes_by_year = {}\n",
        "for file_path in laps_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    size_mb = file_path.stat().st_size / (1024 * 1024)\n",
        "    size_gb = size_mb / 1024\n",
        "    total_size += size_mb\n",
        "    file_sizes_by_year[year] = size_mb\n",
        "    \n",
        "    print(f\"{file_path.name:30s} {size_mb:>10.2f} MB ({size_gb:>6.3f} GB)\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Total':30s} {total_size:>10.2f} MB ({total_size/1024:>6.3f} GB)\")\n",
        "print(f\"\\nNumber of files: {len(laps_files)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Column Discovery and Data Structure\n",
        "Explore the structure of laps data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing structure of: ALL_LAPS_2018.csv\n",
            "============================================================\n",
            "\n",
            "Columns (34):\n",
            "   1. Time                           object            0.0% null\n",
            "   2. Driver                         object            0.0% null\n",
            "   3. DriverNumber                   int64             0.0% null\n",
            "   4. LapTime                        object            1.0% null\n",
            "   5. LapNumber                      float64           0.0% null\n",
            "   6. Stint                          float64           3.0% null\n",
            "   7. PitOutTime                     object           98.0% null\n",
            "   8. PitInTime                      object           97.0% null\n",
            "   9. Sector1Time                    object            3.0% null\n",
            "  10. Sector2Time                    object            0.0% null\n",
            "  11. Sector3Time                    object            1.0% null\n",
            "  12. Sector1SessionTime             object            3.0% null\n",
            "  13. Sector2SessionTime             object            0.0% null\n",
            "  14. Sector3SessionTime             object            1.0% null\n",
            "  15. SpeedI1                        float64          13.0% null\n",
            "  16. SpeedI2                        float64           0.0% null\n",
            "  17. SpeedFL                        float64           3.0% null\n",
            "  18. SpeedST                        float64          13.0% null\n",
            "  19. IsPersonalBest                 bool              0.0% null\n",
            "  20. Compound                       object            3.0% null\n",
            "  21. TyreLife                       float64           3.0% null\n",
            "  22. FreshTyre                      bool              0.0% null\n",
            "  23. Team                           object            0.0% null\n",
            "  24. LapStartTime                   object            0.0% null\n",
            "  25. LapStartDate                   object            0.0% null\n",
            "  26. TrackStatus                    float64          12.0% null\n",
            "  27. Position                       float64           0.0% null\n",
            "  28. Deleted                        float64         100.0% null\n",
            "  29. DeletedReason                  float64         100.0% null\n",
            "  30. FastF1Generated                bool              0.0% null\n",
            "  31. IsAccurate                     bool              0.0% null\n",
            "  32. Year                           int64             0.0% null\n",
            "  33. Event                          object            0.0% null\n",
            "  34. Session                        object            0.0% null\n",
            "\n",
            "Data types:\n",
            "Time                   object\n",
            "Driver                 object\n",
            "DriverNumber            int64\n",
            "LapTime                object\n",
            "LapNumber             float64\n",
            "Stint                 float64\n",
            "PitOutTime             object\n",
            "PitInTime              object\n",
            "Sector1Time            object\n",
            "Sector2Time            object\n",
            "Sector3Time            object\n",
            "Sector1SessionTime     object\n",
            "Sector2SessionTime     object\n",
            "Sector3SessionTime     object\n",
            "SpeedI1               float64\n",
            "SpeedI2               float64\n",
            "SpeedFL               float64\n",
            "SpeedST               float64\n",
            "IsPersonalBest           bool\n",
            "Compound               object\n",
            "TyreLife              float64\n",
            "FreshTyre                bool\n",
            "Team                   object\n",
            "LapStartTime           object\n",
            "LapStartDate           object\n",
            "TrackStatus           float64\n",
            "Position              float64\n",
            "Deleted               float64\n",
            "DeletedReason         float64\n",
            "FastF1Generated          bool\n",
            "IsAccurate               bool\n",
            "Year                    int64\n",
            "Event                  object\n",
            "Session                object\n",
            "dtype: object\n",
            "\n",
            "Memory usage: 0.11 MB (for 100 rows)\n",
            "\n",
            "Sample data (first 5 rows):\n",
            "                     Time Driver  DriverNumber                 LapTime  \\\n",
            "0  0 days 00:08:53.226000    GAS            10  0 days 00:01:45.060000   \n",
            "1  0 days 00:10:26.598000    GAS            10  0 days 00:01:33.372000   \n",
            "2  0 days 00:11:59.459000    GAS            10  0 days 00:01:32.861000   \n",
            "3  0 days 00:13:31.643000    GAS            10  0 days 00:01:32.184000   \n",
            "4  0 days 00:15:03.975000    GAS            10  0 days 00:01:32.332000   \n",
            "\n",
            "   LapNumber  Stint PitOutTime PitInTime             Sector1Time  \\\n",
            "0        1.0    NaN        NaN       NaN                     NaN   \n",
            "1        2.0    1.0        NaN       NaN  0 days 00:00:31.357000   \n",
            "2        3.0    1.0        NaN       NaN  0 days 00:00:31.160000   \n",
            "3        4.0    1.0        NaN       NaN  0 days 00:00:30.835000   \n",
            "4        5.0    1.0        NaN       NaN  0 days 00:00:30.716000   \n",
            "\n",
            "              Sector2Time  ...             LapStartDate TrackStatus Position  \\\n",
            "0  0 days 00:00:25.495000  ...  2018-03-25 05:13:19.169         NaN     17.0   \n",
            "1  0 days 00:00:24.825000  ...  2018-03-25 05:15:04.407         NaN     17.0   \n",
            "2  0 days 00:00:24.725000  ...  2018-03-25 05:16:37.779         NaN     17.0   \n",
            "3  0 days 00:00:24.730000  ...  2018-03-25 05:18:10.640         NaN     17.0   \n",
            "4  0 days 00:00:24.821000  ...  2018-03-25 05:19:42.824        21.0     17.0   \n",
            "\n",
            "  Deleted  DeletedReason  FastF1Generated  IsAccurate  Year  \\\n",
            "0     NaN            NaN            False       False  2018   \n",
            "1     NaN            NaN            False       False  2018   \n",
            "2     NaN            NaN            False       False  2018   \n",
            "3     NaN            NaN            False       False  2018   \n",
            "4     NaN            NaN            False        True  2018   \n",
            "\n",
            "                   Event Session  \n",
            "0  Australian Grand Prix       R  \n",
            "1  Australian Grand Prix       R  \n",
            "2  Australian Grand Prix       R  \n",
            "3  Australian Grand Prix       R  \n",
            "4  Australian Grand Prix       R  \n",
            "\n",
            "[5 rows x 34 columns]\n",
            "\n",
            "Data summary:\n",
            "                          Time Driver  DriverNumber                 LapTime  \\\n",
            "count                      100    100    100.000000                      99   \n",
            "unique                     100      3           NaN                      98   \n",
            "top     0 days 00:08:53.226000    PER           NaN  0 days 00:01:30.922000   \n",
            "freq                         1     58           NaN                       2   \n",
            "mean                       NaN    NaN     11.700000                     NaN   \n",
            "std                        NaN    NaN      1.480513                     NaN   \n",
            "min                        NaN    NaN     10.000000                     NaN   \n",
            "25%                        NaN    NaN     11.000000                     NaN   \n",
            "50%                        NaN    NaN     11.000000                     NaN   \n",
            "75%                        NaN    NaN     14.000000                     NaN   \n",
            "max                        NaN    NaN     14.000000                     NaN   \n",
            "\n",
            "         LapNumber      Stint              PitOutTime               PitInTime  \\\n",
            "count   100.000000  97.000000                       2                       3   \n",
            "unique         NaN        NaN                       2                       3   \n",
            "top            NaN        NaN  0 days 00:44:03.316000  0 days 00:29:16.873000   \n",
            "freq           NaN        NaN                       1                       1   \n",
            "mean     22.220000   1.371134                     NaN                     NaN   \n",
            "std      16.232266   0.485618                     NaN                     NaN   \n",
            "min       1.000000   1.000000                     NaN                     NaN   \n",
            "25%       9.000000   1.000000                     NaN                     NaN   \n",
            "50%      18.500000   1.000000                     NaN                     NaN   \n",
            "75%      33.250000   2.000000                     NaN                     NaN   \n",
            "max      58.000000   2.000000                     NaN                     NaN   \n",
            "\n",
            "                   Sector1Time             Sector2Time  ...  \\\n",
            "count                       97                     100  ...   \n",
            "unique                      93                      98  ...   \n",
            "top     0 days 00:00:30.141000  0 days 00:00:24.244000  ...   \n",
            "freq                         3                       2  ...   \n",
            "mean                       NaN                     NaN  ...   \n",
            "std                        NaN                     NaN  ...   \n",
            "min                        NaN                     NaN  ...   \n",
            "25%                        NaN                     NaN  ...   \n",
            "50%                        NaN                     NaN  ...   \n",
            "75%                        NaN                     NaN  ...   \n",
            "max                        NaN                     NaN  ...   \n",
            "\n",
            "                   LapStartDate TrackStatus    Position Deleted  \\\n",
            "count                       100   88.000000  100.000000     0.0   \n",
            "unique                       98         NaN         NaN     NaN   \n",
            "top     2018-03-25 05:13:19.169         NaN         NaN     NaN   \n",
            "freq                          3         NaN         NaN     NaN   \n",
            "mean                        NaN    7.397727   11.380000     NaN   \n",
            "std                         NaN   17.292972    2.577212     NaN   \n",
            "min                         NaN    1.000000    5.000000     NaN   \n",
            "25%                         NaN    1.000000   10.000000     NaN   \n",
            "50%                         NaN    1.000000   11.000000     NaN   \n",
            "75%                         NaN    4.000000   12.000000     NaN   \n",
            "max                         NaN  126.000000   18.000000     NaN   \n",
            "\n",
            "        DeletedReason  FastF1Generated  IsAccurate    Year  \\\n",
            "count             0.0              100         100   100.0   \n",
            "unique            NaN                1           2     NaN   \n",
            "top               NaN            False        True     NaN   \n",
            "freq              NaN              100          76     NaN   \n",
            "mean              NaN              NaN         NaN  2018.0   \n",
            "std               NaN              NaN         NaN     0.0   \n",
            "min               NaN              NaN         NaN  2018.0   \n",
            "25%               NaN              NaN         NaN  2018.0   \n",
            "50%               NaN              NaN         NaN  2018.0   \n",
            "75%               NaN              NaN         NaN  2018.0   \n",
            "max               NaN              NaN         NaN  2018.0   \n",
            "\n",
            "                        Event Session  \n",
            "count                     100     100  \n",
            "unique                      1       1  \n",
            "top     Australian Grand Prix       R  \n",
            "freq                      100     100  \n",
            "mean                      NaN     NaN  \n",
            "std                       NaN     NaN  \n",
            "min                       NaN     NaN  \n",
            "25%                       NaN     NaN  \n",
            "50%                       NaN     NaN  \n",
            "75%                       NaN     NaN  \n",
            "max                       NaN     NaN  \n",
            "\n",
            "[11 rows x 34 columns]\n"
          ]
        }
      ],
      "source": [
        "# Load a sample from first file to understand structure\n",
        "test_file = laps_files[0] if laps_files else None\n",
        "\n",
        "if test_file:\n",
        "    print(f\"Analyzing structure of: {test_file.name}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Read first few rows\n",
        "    sample_df = pd.read_csv(test_file, nrows=100)\n",
        "    \n",
        "    print(f\"\\nColumns ({len(sample_df.columns)}):\")\n",
        "    for i, col in enumerate(sample_df.columns, 1):\n",
        "        dtype = sample_df[col].dtype\n",
        "        null_pct = (sample_df[col].isnull().sum() / len(sample_df)) * 100\n",
        "        print(f\"  {i:2d}. {col:30s} {str(dtype):15s} {null_pct:5.1f}% null\")\n",
        "    \n",
        "    print(f\"\\nData types:\")\n",
        "    print(sample_df.dtypes)\n",
        "    \n",
        "    print(f\"\\nMemory usage: {sample_df.memory_usage(deep=True).sum() / (1024 * 1024):.2f} MB (for 100 rows)\")\n",
        "    \n",
        "    print(f\"\\nSample data (first 5 rows):\")\n",
        "    print(sample_df.head())\n",
        "    \n",
        "    print(f\"\\nData summary:\")\n",
        "    print(sample_df.describe(include='all'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Row Count Comparison Across Years\n",
        "Compare row counts for all laps files across different years to understand data volume trends and consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row Count Comparison by Year:\n",
            "======================================================================\n",
            "\n",
            "2018: ALL_LAPS_2018.csv\n",
            "  File size: 19.27 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 58,002\n",
            "  ✓ Rows per MB: 3,010\n",
            "\n",
            "2019: ALL_LAPS_2019.csv\n",
            "  File size: 14.97 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 45,169\n",
            "  ✓ Rows per MB: 3,018\n",
            "\n",
            "2020: ALL_LAPS_2020.csv\n",
            "  File size: 12.95 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 39,040\n",
            "  ✓ Rows per MB: 3,015\n",
            "\n",
            "2021: ALL_LAPS_2021.csv\n",
            "  File size: 20.34 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 60,296\n",
            "  ✓ Rows per MB: 2,964\n",
            "\n",
            "2022: ALL_LAPS_2022.csv\n",
            "  File size: 18.74 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 59,565\n",
            "  ✓ Rows per MB: 3,178\n",
            "\n",
            "2023: ALL_LAPS_2023.csv\n",
            "  File size: 19.34 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 57,491\n",
            "  ✓ Rows per MB: 2,973\n",
            "\n",
            "2024: ALL_LAPS_2024.csv\n",
            "  File size: 21.06 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 62,690\n",
            "  ✓ Rows per MB: 2,977\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - Row Counts by Year:\n",
            "======================================================================\n",
            "\n",
            "Year           Row Count     File Size (MB)      Rows/MB   % of Total\n",
            "----------------------------------------------------------------------\n",
            "2018              58,002              19.27        3,010       15.17%\n",
            "2019              45,169              14.97        3,018       11.82%\n",
            "2020              39,040              12.95        3,015       10.21%\n",
            "2021              60,296              20.34        2,964       15.77%\n",
            "2022              59,565              18.74        3,178       15.58%\n",
            "2023              57,491              19.34        2,973       15.04%\n",
            "2024              62,690              21.06        2,977       16.40%\n",
            "----------------------------------------------------------------------\n",
            "TOTAL            382,253             126.66        3,018       100.00%\n",
            "\n",
            "Maximum rows: 2024 with 62,690 rows\n",
            "Minimum rows: 2020 with 39,040 rows\n",
            "Range: 23,650 rows (60.6% difference)\n",
            "\n",
            "Consistency check:\n",
            "  Median rows: 58,002\n",
            "  Standard deviation: 8,884\n",
            "  Coefficient of variation: 15.3%\n",
            "  ⚠️  Moderate variation - check for missing events or sessions\n"
          ]
        }
      ],
      "source": [
        "# Count rows for all laps files\n",
        "print(\"Row Count Comparison by Year:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "row_counts_by_year = {}\n",
        "\n",
        "for file_path in laps_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    file_size_mb = file_sizes_by_year[year]\n",
        "    \n",
        "    print(f\"\\n{year}: {file_path.name}\")\n",
        "    print(f\"  File size: {file_size_mb:.2f} MB\")\n",
        "    print(f\"  Counting rows...\")\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        row_count = len(df)\n",
        "        row_counts_by_year[year] = row_count\n",
        "        \n",
        "        print(f\"  ✓ Total rows: {row_count:,}\")\n",
        "        \n",
        "        # Calculate rows per MB\n",
        "        rows_per_mb = row_count / file_size_mb if file_size_mb > 0 else 0\n",
        "        print(f\"  ✓ Rows per MB: {rows_per_mb:,.0f}\")\n",
        "        \n",
        "        # Clear from memory\n",
        "        del df\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SUMMARY - Row Counts by Year:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create comparison DataFrame\n",
        "if row_counts_by_year:\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Year': list(row_counts_by_year.keys()),\n",
        "        'Row_Count': list(row_counts_by_year.values()),\n",
        "        'File_Size_MB': [file_sizes_by_year.get(year, 0) for year in row_counts_by_year.keys()]\n",
        "    })\n",
        "    \n",
        "    # Sort by year\n",
        "    comparison_df = comparison_df.sort_values('Year')\n",
        "    \n",
        "    # Calculate additional metrics\n",
        "    comparison_df['Rows_Per_MB'] = comparison_df['Row_Count'] / comparison_df['File_Size_MB']\n",
        "    comparison_df['Pct_of_Total'] = (comparison_df['Row_Count'] / comparison_df['Row_Count'].sum() * 100).round(2)\n",
        "    \n",
        "    # Display formatted table\n",
        "    print(f\"\\n{'Year':<8} {'Row Count':>15} {'File Size (MB)':>18} {'Rows/MB':>12} {'% of Total':>12}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    for _, row in comparison_df.iterrows():\n",
        "        print(f\"{row['Year']:<8} {row['Row_Count']:>15,} {row['File_Size_MB']:>18,.2f} \"\n",
        "              f\"{row['Rows_Per_MB']:>12,.0f} {row['Pct_of_Total']:>11.2f}%\")\n",
        "    \n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'TOTAL':<8} {comparison_df['Row_Count'].sum():>15,} {comparison_df['File_Size_MB'].sum():>18,.2f} \"\n",
        "          f\"{comparison_df['Row_Count'].sum() / comparison_df['File_Size_MB'].sum():>12,.0f} {'100.00':>12}%\")\n",
        "    \n",
        "    # Find min/max\n",
        "    max_year = comparison_df.loc[comparison_df['Row_Count'].idxmax(), 'Year']\n",
        "    max_rows = comparison_df['Row_Count'].max()\n",
        "    min_year = comparison_df.loc[comparison_df['Row_Count'].idxmin(), 'Year']\n",
        "    min_rows = comparison_df['Row_Count'].min()\n",
        "    \n",
        "    print(f\"\\nMaximum rows: {max_year} with {max_rows:,} rows\")\n",
        "    print(f\"Minimum rows: {min_year} with {min_rows:,} rows\")\n",
        "    print(f\"Range: {max_rows - min_rows:,} rows ({((max_rows / min_rows - 1) * 100):.1f}% difference)\")\n",
        "    \n",
        "    # Check for consistency\n",
        "    median_rows = comparison_df['Row_Count'].median()\n",
        "    std_rows = comparison_df['Row_Count'].std()\n",
        "    cv = (std_rows / median_rows * 100) if median_rows > 0 else 0\n",
        "    \n",
        "    print(f\"\\nConsistency check:\")\n",
        "    print(f\"  Median rows: {median_rows:,.0f}\")\n",
        "    print(f\"  Standard deviation: {std_rows:,.0f}\")\n",
        "    print(f\"  Coefficient of variation: {cv:.1f}%\")\n",
        "    \n",
        "    if cv > 30:\n",
        "        print(f\"  ⚠️  High variation detected - may indicate data completeness issues\")\n",
        "    elif cv > 15:\n",
        "        print(f\"  ⚠️  Moderate variation - check for missing events or sessions\")\n",
        "    else:\n",
        "        print(f\"  ✓ Low variation - data appears consistent across years\")\n",
        "    \n",
        "    # Store for later use\n",
        "    laps_row_counts = comparison_df\n",
        "else:\n",
        "    print(\"No row counts available\")\n",
        "    laps_row_counts = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Expected races per year (from known F1 calendar)\n",
        "expected_races = {\n",
        "    '2018': 21,\n",
        "    '2019': 21,\n",
        "    '2020': 17,  # COVID-19 shortened season\n",
        "    '2021': 22,\n",
        "    '2022': 22,\n",
        "    '2023': 22,\n",
        "    '2024': 24\n",
        "}\n",
        "\n",
        "# Expected sessions per race (typically: FP1, FP2, FP3, Q, R)\n",
        "expected_sessions_per_race = 5\n",
        "# Expected drivers per race (typically 20-22)\n",
        "expected_drivers_per_race = 20\n",
        "\n",
        "print(\"Data Completeness Validation:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Extract unique events, sessions, and drivers from laps data\n",
        "laps_coverage = {}\n",
        "\n",
        "for file_path in laps_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    print(f\"\\n{year}: Analyzing coverage...\")\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        unique_events = df['Event'].unique() if 'Event' in df.columns else []\n",
        "        unique_sessions = df['Session'].unique() if 'Session' in df.columns else []\n",
        "        unique_drivers = df['Driver'].unique() if 'Driver' in df.columns else []\n",
        "        \n",
        "        # Count unique event-session combinations\n",
        "        if 'Event' in df.columns and 'Session' in df.columns:\n",
        "            event_session_counts = df.groupby(['Event', 'Session']).size()\n",
        "            unique_combinations = len(event_session_counts)\n",
        "        else:\n",
        "            unique_combinations = 0\n",
        "        \n",
        "        # Calculate average laps per driver per session\n",
        "        if 'Event' in df.columns and 'Session' in df.columns and 'Driver' in df.columns:\n",
        "            laps_per_driver_session = df.groupby(['Event', 'Session', 'Driver']).size()\n",
        "            avg_laps = laps_per_driver_session.mean() if len(laps_per_driver_session) > 0 else 0\n",
        "        else:\n",
        "            avg_laps = 0\n",
        "        \n",
        "        laps_coverage[year] = {\n",
        "            'unique_events': len(unique_events),\n",
        "            'unique_sessions': len(unique_sessions),\n",
        "            'unique_drivers': len(unique_drivers),\n",
        "            'events': sorted(unique_events),\n",
        "            'sessions': sorted(unique_sessions),\n",
        "            'drivers': sorted(unique_drivers),\n",
        "            'event_session_combinations': unique_combinations,\n",
        "            'avg_laps_per_driver_session': avg_laps,\n",
        "            'total_rows': len(df)\n",
        "        }\n",
        "        \n",
        "        print(f\"  Found {len(unique_events)} unique events\")\n",
        "        print(f\"  Found {len(unique_sessions)} unique sessions: {sorted(unique_sessions)}\")\n",
        "        print(f\"  Found {len(unique_drivers)} unique drivers\")\n",
        "        print(f\"  Found {unique_combinations} unique event-session combinations\")\n",
        "        print(f\"  Average laps per driver per session: {avg_laps:.1f}\")\n",
        "        print(f\"  Total rows: {len(df):,}\")\n",
        "        \n",
        "        # Clear from memory\n",
        "        del df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "        laps_coverage[year] = None\n",
        "\n",
        "# Validation: Compare against expected\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPLETENESS CHECK:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n{'Year':<8} {'Expected Races':>15} {'Found Events':>15} {'Difference':>12} {'Status':>15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "completeness_issues = []\n",
        "\n",
        "for year in sorted(laps_coverage.keys()):\n",
        "    if laps_coverage[year] is None:\n",
        "        continue\n",
        "    \n",
        "    found_events = laps_coverage[year]['unique_events']\n",
        "    expected = expected_races.get(year, 0)\n",
        "    diff = found_events - expected\n",
        "    \n",
        "    if expected > 0:\n",
        "        if diff == 0:\n",
        "            status = \"✓ Complete\"\n",
        "        elif diff < 0:\n",
        "            status = f\"⚠ Missing {abs(diff)}\"\n",
        "            completeness_issues.append({\n",
        "                'year': year,\n",
        "                'issue': f\"Missing {abs(diff)} race(s). Expected {expected}, found {found_events}\"\n",
        "            })\n",
        "        else:\n",
        "            status = f\"+{diff} extra\"\n",
        "    else:\n",
        "        status = \"? Unknown\"\n",
        "    \n",
        "    print(f\"{year:<8} {expected:>15} {found_events:>15} {diff:>+12} {status:>15}\")\n",
        "\n",
        "# Calculate rows per race (normalized)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ROWS PER RACE (Normalized for comparison):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n{'Year':<8} {'Total Rows':>15} {'Events Found':>15} {'Drivers':>10} {'Rows/Race':>15} {'Relative':>12}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "rows_per_race_by_year = {}\n",
        "\n",
        "for year in sorted(laps_coverage.keys()):\n",
        "    if laps_coverage[year] is None:\n",
        "        continue\n",
        "    \n",
        "    total_rows = laps_coverage[year]['total_rows']\n",
        "    events = laps_coverage[year]['unique_events']\n",
        "    drivers = laps_coverage[year]['unique_drivers']\n",
        "    \n",
        "    if events > 0:\n",
        "        rows_per_race = total_rows / events\n",
        "        rows_per_race_by_year[year] = rows_per_race\n",
        "        \n",
        "        # Calculate relative to median for comparison\n",
        "        if len(rows_per_race_by_year) > 1:\n",
        "            median_rpr = np.median(list(rows_per_race_by_year.values()))\n",
        "            relative = (rows_per_race / median_rpr * 100) if median_rpr > 0 else 100\n",
        "        else:\n",
        "            relative = 100\n",
        "        \n",
        "        print(f\"{year:<8} {total_rows:>15,} {events:>15} {drivers:>10} {rows_per_race:>15,.0f} {relative:>11.0f}%\")\n",
        "\n",
        "# Flag significant variations\n",
        "if len(rows_per_race_by_year) > 1:\n",
        "    median_rpr = np.median(list(rows_per_race_by_year.values()))\n",
        "    std_rpr = np.std(list(rows_per_race_by_year.values()))\n",
        "    \n",
        "    print(\"\\n⚠️  VARIATION ANALYSIS:\")\n",
        "    for year in sorted(rows_per_race_by_year.keys()):\n",
        "        rpr = rows_per_race_by_year[year]\n",
        "        deviation = abs(rpr - median_rpr) / median_rpr * 100 if median_rpr > 0 else 0\n",
        "        \n",
        "        if deviation > 30:  # More than 30% deviation\n",
        "            print(f\"  {year}: {deviation:.1f}% deviation from median ({median_rpr:.0f} rows/race)\")\n",
        "            print(f\"    Possible causes: Different number of drivers, missing sessions, or data quality issues\")\n",
        "        elif deviation > 15:\n",
        "            print(f\"  {year}: {deviation:.1f}% deviation (moderate - may be normal variation)\")\n",
        "\n",
        "# Summary of issues\n",
        "if completeness_issues:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"⚠️  DATA COMPLETENESS ISSUES DETECTED:\")\n",
        "    print(\"=\" * 80)\n",
        "    for issue in completeness_issues:\n",
        "        print(f\"  {issue['year']}: {issue['issue']}\")\n",
        "else:\n",
        "    print(\"\\n✅ No major completeness issues detected in event coverage.\")\n",
        "    print(\"   Row count variations likely due to:\")\n",
        "    print(\"   - Different number of races per year (normal)\")\n",
        "    print(\"   - Different number of drivers per year (normal)\")\n",
        "    print(\"   - Different session lengths/lap counts (normal)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze laps features across years\n",
        "print(\"Laps Feature Analysis:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Sample from each year to check feature consistency\n",
        "feature_summary = {}\n",
        "\n",
        "for file_path in laps_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    print(f\"\\n{year}: Analyzing features...\")\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        # Numeric columns summary (sample statistics)\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        \n",
        "        # Exclude Year if it's numeric, and exclude DriverNumber if present\n",
        "        if 'Year' in numeric_cols:\n",
        "            numeric_cols.remove('Year')\n",
        "        if 'DriverNumber' in numeric_cols:\n",
        "            numeric_cols.remove('DriverNumber')\n",
        "        \n",
        "        feature_summary[year] = {}\n",
        "        \n",
        "        print(f\"  Numeric features: {numeric_cols[:10]}...\")  # Show first 10\n",
        "        \n",
        "        # Sample key numeric features\n",
        "        key_features = ['LapTime', 'LapNumber', 'TyreLife', 'Sector1Time', 'Sector2Time', 'Sector3Time']\n",
        "        for col in key_features:\n",
        "            if col in df.columns:\n",
        "                feature_summary[year][col] = {\n",
        "                    'mean': df[col].mean() if pd.api.types.is_numeric_dtype(df[col]) else None,\n",
        "                    'std': df[col].std() if pd.api.types.is_numeric_dtype(df[col]) else None,\n",
        "                    'min': df[col].min() if pd.api.types.is_numeric_dtype(df[col]) else None,\n",
        "                    'max': df[col].max() if pd.api.types.is_numeric_dtype(df[col]) else None,\n",
        "                    'null_pct': (df[col].isnull().sum() / len(df)) * 100\n",
        "                }\n",
        "                if feature_summary[year][col]['mean'] is not None:\n",
        "                    print(f\"    {col}: mean={feature_summary[year][col]['mean']:.2f}, \"\n",
        "                          f\"std={feature_summary[year][col]['std']:.2f}, \"\n",
        "                          f\"null={feature_summary[year][col]['null_pct']:.1f}%\")\n",
        "        \n",
        "        # Categorical columns\n",
        "        categorical_cols = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "        exclude_cols = ['Year', 'Event', 'Session', 'Driver', 'Team']\n",
        "        categorical_cols = [c for c in categorical_cols if c not in exclude_cols]\n",
        "        \n",
        "        print(f\"  Categorical features: {categorical_cols[:5]}...\")  # Show first 5\n",
        "        for col in categorical_cols[:5]:\n",
        "            if col in df.columns:\n",
        "                unique_count = df[col].nunique()\n",
        "                print(f\"    {col}: {unique_count} unique values\")\n",
        "        \n",
        "        del df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "\n",
        "# Cross-year consistency check for key features\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CROSS-YEAR CONSISTENCY CHECK:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if feature_summary:\n",
        "    # Check if all years have same features\n",
        "    all_features = set()\n",
        "    for year_data in feature_summary.values():\n",
        "        all_features.update(year_data.keys())\n",
        "    \n",
        "    print(f\"\\nKey numeric features found: {sorted(all_features)}\")\n",
        "    \n",
        "    # Check consistency of feature ranges\n",
        "    print(\"\\nFeature range consistency:\")\n",
        "    for feature in sorted(all_features):\n",
        "        print(f\"\\n  {feature}:\")\n",
        "        years_with_feature = [y for y in feature_summary.keys() if feature in feature_summary[y]]\n",
        "        \n",
        "        if len(years_with_feature) < len(feature_summary):\n",
        "            missing_years = set(feature_summary.keys()) - set(years_with_feature)\n",
        "            print(f\"    ⚠️  Missing in years: {sorted(missing_years)}\")\n",
        "        else:\n",
        "            means = [feature_summary[y][feature]['mean'] for y in years_with_feature \n",
        "                    if feature_summary[y][feature]['mean'] is not None]\n",
        "            \n",
        "            if len(means) > 0:\n",
        "                mean_of_means = np.mean(means)\n",
        "                std_of_means = np.std(means)\n",
        "                \n",
        "                print(f\"    Mean across years: {mean_of_means:.2f} (std: {std_of_means:.2f})\")\n",
        "                \n",
        "                if std_of_means / abs(mean_of_means) > 0.5 if mean_of_means != 0 else False:  # High variation\n",
        "                    print(f\"    ⚠️  High variation in means across years\")\n",
        "                \n",
        "                # Check for outliers\n",
        "                for year in years_with_feature:\n",
        "                    year_mean = feature_summary[year][feature]['mean']\n",
        "                    if year_mean is not None:\n",
        "                        z_score = abs(year_mean - mean_of_means) / std_of_means if std_of_means > 0 else 0\n",
        "                        if z_score > 2:\n",
        "                            print(f\"    ⚠️  {year}: Outlier (z-score: {z_score:.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualization (Optional)\n",
        "Visualize row counts and data distribution if matplotlib is available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Visualize row counts comparison (if matplotlib is available)\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    if laps_row_counts is not None:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Plot 1: Row counts by year\n",
        "        ax1.bar(laps_row_counts['Year'].astype(str), laps_row_counts['Row_Count'], \n",
        "                color='steelblue', alpha=0.7)\n",
        "        ax1.set_xlabel('Year', fontsize=12)\n",
        "        ax1.set_ylabel('Row Count', fontsize=12)\n",
        "        ax1.set_title('Laps Row Counts by Year', fontsize=14, fontweight='bold')\n",
        "        ax1.grid(axis='y', alpha=0.3)\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for idx, row in laps_row_counts.iterrows():\n",
        "            height = row['Row_Count']\n",
        "            ax1.text(row['Year'], height, f'{height/1e3:.0f}K', \n",
        "                    ha='center', va='bottom', fontsize=9, rotation=90)\n",
        "        \n",
        "        # Plot 2: Rows per race (normalized)\n",
        "        if rows_per_race_by_year:\n",
        "            years = sorted(rows_per_race_by_year.keys())\n",
        "            rpr_values = [rows_per_race_by_year[y] for y in years]\n",
        "            \n",
        "            ax2.bar([str(y) for y in years], rpr_values, color='coral', alpha=0.7)\n",
        "            ax2.set_xlabel('Year', fontsize=12)\n",
        "            ax2.set_ylabel('Rows per Race', fontsize=12)\n",
        "            ax2.set_title('Normalized Rows per Race', fontsize=14, fontweight='bold')\n",
        "            ax2.grid(axis='y', alpha=0.3)\n",
        "            \n",
        "            # Add value labels\n",
        "            for year, value in zip(years, rpr_values):\n",
        "                ax2.text(str(year), value, f'{value/1e3:.0f}K', \n",
        "                        ha='center', va='bottom', fontsize=9)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"Visualization created successfully!\")\n",
        "    else:\n",
        "        print(\"No data available for visualization\")\n",
        "        \n",
        "except ImportError:\n",
        "    print(\"Matplotlib not available - skipping visualization\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating visualization: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary and Feature Extraction Recommendations\n",
        "Summarize findings and recommend features for extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"LAPS DATA SUMMARY AND RECOMMENDATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. AVAILABLE FEATURES:\")\n",
        "print(\"-\" * 80)\n",
        "if test_file:\n",
        "    sample = pd.read_csv(test_file, nrows=1)\n",
        "    print(\"Columns available:\")\n",
        "    for col in sample.columns:\n",
        "        print(f\"  - {col}\")\n",
        "\n",
        "print(\"\\n2. POTENTIAL FEATURES FOR EXTRACTION:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"Based on analysis, recommended features:\")\n",
        "print(\"  - Lap performance: LapTime, LapNumber, Sector1Time, Sector2Time, Sector3Time\")\n",
        "print(\"  - Speed metrics: SpeedI1, SpeedI2, SpeedFL, SpeedST\")\n",
        "print(\"  - Tyre data: Compound, TyreLife, FreshTyre\")\n",
        "print(\"  - Position data: Position\")\n",
        "print(\"  - Stint data: Stint, PitOutTime, PitInTime\")\n",
        "print(\"  - Flags: IsPersonalBest, Deleted, FastF1Generated, IsAccurate\")\n",
        "print(\"  - Context: Year, Event, Session, Driver, DriverNumber, Team\")\n",
        "print(\"  - Derived: Lap delta, sector deltas, consistency metrics, tyre degradation\")\n",
        "\n",
        "print(\"\\n3. DATA QUALITY:\")\n",
        "print(\"-\" * 80)\n",
        "if completeness_issues:\n",
        "    print(\"  ⚠️  Issues found - review completeness section above\")\n",
        "else:\n",
        "    print(\"  ✓ No major data quality issues detected\")\n",
        "\n",
        "if laps_row_counts is not None:\n",
        "    cv = (laps_row_counts['Row_Count'].std() / laps_row_counts['Row_Count'].mean() * 100)\n",
        "    print(f\"  Consistency (CV): {cv:.1f}%\")\n",
        "    if cv > 30:\n",
        "        print(\"  ⚠️  High variation - investigate specific years\")\n",
        "\n",
        "print(\"\\n4. FEATURE EXTRACTION STRATEGY:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"  - Group by: Year, Event, Session, Driver\")\n",
        "print(\"  - Aggregate: Mean, Min, Max, Std for lap times and speeds\")\n",
        "print(\"  - Count features: Total laps, personal bests, deleted laps\")\n",
        "print(\"  - Tyre features: Average tyre life, compound distribution\")\n",
        "print(\"  - Position features: Average position, position changes\")\n",
        "print(\"  - Join key: Year + Event + Session + Driver (matches RESULTS)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
