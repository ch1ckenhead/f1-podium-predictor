{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Data Verification\n",
        "\n",
        "This notebook performs comprehensive data quality and consistency verification for both Kaggle (Ergast) and FastF1 datasets. It checks:\n",
        "\n",
        "1. **Completeness**: Year coverage, race coverage, driver/constructor metadata\n",
        "2. **Data Quality**: Missing values, outliers, data types, range validation\n",
        "3. **Cross-Source Consistency**: Matching between Kaggle and FastF1 data (2018-2024 overlap)\n",
        "\n",
        "The goal is to identify any data issues before combining datasets in the next notebook.\n",
        "\n",
        "**How to use this notebook:**\n",
        "- Run each cell sequentially\n",
        "- After each code cell, read the markdown note that follows to understand what the output means\n",
        "- Look for warning signs mentioned in the notes\n",
        "- The final report summarizes all findings for future reference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle data: C:\\Users\\erikv\\Downloads\\F1\\data\\raw\\kaggle\n",
            "FastF1 data: C:\\Users\\erikv\\Downloads\\F1\\data\\raw\\fastf1_2018plus\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up paths using pathlib.Path for proper path joining\n",
        "PROJECT_ROOT = Path(r\"C:\\Users\\erikv\\Downloads\\F1\")\n",
        "KAGGLE_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / \"kaggle\"\n",
        "FASTF1_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / \"fastf1_2018plus\"\n",
        "PROCESSED_ROOT = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "PROCESSED_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Kaggle data: {KAGGLE_ROOT}\")\n",
        "print(f\"FastF1 data: {FASTF1_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading & Overview\n",
        "\n",
        "Load all Kaggle CSVs and FastF1 CSVs, display basic statistics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded races: 1,125 rows, 18 columns\n",
            "Loaded results: 26,759 rows, 18 columns\n",
            "Loaded drivers: 861 rows, 9 columns\n",
            "Loaded constructors: 212 rows, 5 columns\n",
            "Loaded circuits: 77 rows, 9 columns\n",
            "Loaded qualifying: 10,494 rows, 9 columns\n",
            "Loaded driver_standings: 34,863 rows, 7 columns\n",
            "Loaded constructor_standings: 13,391 rows, 7 columns\n",
            "Loaded constructor_results: 12,625 rows, 5 columns\n",
            "Loaded sprint_results: 360 rows, 16 columns\n",
            "Loaded pit_stops: 11,371 rows, 7 columns\n",
            "Loaded lap_times: 589,081 rows, 6 columns\n",
            "\n",
            "Total Kaggle datasets loaded: 12\n"
          ]
        }
      ],
      "source": [
        "# Modular function to load Kaggle CSV\n",
        "def load_kaggle_csv(name, path=None):\n",
        "    \"\"\"Load a Kaggle CSV file and return DataFrame with source tracking.\"\"\"\n",
        "    if path is None:\n",
        "        path = KAGGLE_ROOT / f\"{name}.csv\"\n",
        "    if not path.exists():\n",
        "        print(f\"Warning: {name}.csv not found at {path}\")\n",
        "        return None\n",
        "    df = pd.read_csv(path)\n",
        "    df.attrs['source'] = 'kaggle'\n",
        "    df.attrs['name'] = name\n",
        "    return df\n",
        "\n",
        "# Load all Kaggle CSVs\n",
        "kaggle_files = {\n",
        "    'races': 'races',\n",
        "    'results': 'results',\n",
        "    'drivers': 'drivers',\n",
        "    'constructors': 'constructors',\n",
        "    'circuits': 'circuits',\n",
        "    'qualifying': 'qualifying',\n",
        "    'driver_standings': 'driver_standings',\n",
        "    'constructor_standings': 'constructor_standings',\n",
        "    'constructor_results': 'constructor_results',\n",
        "    'sprint_results': 'sprint_results',\n",
        "    'pit_stops': 'pit_stops',\n",
        "    'lap_times': 'lap_times'\n",
        "}\n",
        "\n",
        "kaggle_data = {}\n",
        "for key, filename in kaggle_files.items():\n",
        "    df = load_kaggle_csv(filename)\n",
        "    if df is not None:\n",
        "        kaggle_data[key] = df\n",
        "        print(f\"Loaded {key}: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
        "\n",
        "print(f\"\\nTotal Kaggle datasets loaded: {len(kaggle_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastF1 2018 RESULTS: 2,100 rows, 25 columns\n",
            "FastF1 2018 LAPS: 58,002 rows, 34 columns\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path.exists():\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m         fastf1_data[year][dataset] = df\n\u001b[32m     14\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFastF1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:239\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._first_chunk:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:820\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:914\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:331\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Load FastF1 CSVs (2018-2024)\n",
        "fastf1_years = range(2018, 2025)\n",
        "fastf1_datasets = ['RESULTS', 'LAPS', 'TELEMETRY', 'WEATHER']\n",
        "\n",
        "fastf1_data = {}\n",
        "for year in fastf1_years:\n",
        "    fastf1_data[year] = {}\n",
        "    for dataset in fastf1_datasets:\n",
        "        path = FASTF1_ROOT / f\"ALL_{dataset}_{year}.csv\"\n",
        "        if path.exists():\n",
        "            try:\n",
        "                df = pd.read_csv(path, low_memory=False)\n",
        "                fastf1_data[year][dataset] = df\n",
        "                print(f\"FastF1 {year} {dataset}: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading FastF1 {year} {dataset}: {e}\")\n",
        "        else:\n",
        "            print(f\"FastF1 {year} {dataset}: File not found\")\n",
        "\n",
        "print(f\"\\nFastF1 data loaded for years: {list(fastf1_data.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Completeness Checks\n",
        "\n",
        "Check year coverage, race coverage, and metadata completeness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle Data Completeness Summary:\n",
            "                 name   rows  columns  missing_pct  raceId_missing  raceId_missing_pct  year_missing  year_missing_pct  round_missing  round_missing_pct  circuitId_missing  circuitId_missing_pct  resultId_missing  resultId_missing_pct  driverId_missing  driverId_missing_pct  constructorId_missing  constructorId_missing_pct  qualifyId_missing  qualifyId_missing_pct  driverStandingsId_missing  driverStandingsId_missing_pct  constructorStandingsId_missing  constructorStandingsId_missing_pct  constructorResultsId_missing  constructorResultsId_missing_pct\n",
            "                races   1125       18     0.000000             0.0                 0.0           0.0               0.0            0.0                0.0                0.0                    0.0               NaN                   NaN               NaN                   NaN                    NaN                        NaN                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "              results  26759       18     0.000000             0.0                 0.0           NaN               NaN            NaN                NaN                NaN                    NaN               0.0                   0.0               0.0                   0.0                    0.0                        0.0                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "              drivers    861        9     0.000000             NaN                 NaN           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               0.0                   0.0                    NaN                        NaN                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "         constructors    212        5     0.000000             NaN                 NaN           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               NaN                   NaN                    0.0                        0.0                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "             circuits     77        9     0.000000             NaN                 NaN           NaN               NaN            NaN                NaN                0.0                    0.0               NaN                   NaN               NaN                   NaN                    NaN                        NaN                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "           qualifying  10494        9     0.071999             0.0                 0.0           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               0.0                   0.0                    NaN                        NaN                0.0                    0.0                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "     driver_standings  34863        7     0.000000             0.0                 0.0           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               0.0                   0.0                    NaN                        NaN                NaN                    NaN                        0.0                            0.0                             NaN                                 NaN                           NaN                               NaN\n",
            "constructor_standings  13391        7     0.000000             0.0                 0.0           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               NaN                   NaN                    0.0                        0.0                NaN                    NaN                        NaN                            NaN                             0.0                                 0.0                           NaN                               NaN\n",
            "  constructor_results  12625        5     0.000000             0.0                 0.0           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               NaN                   NaN                    0.0                        0.0                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           0.0                               0.0\n",
            "       sprint_results    360       16     0.000000             0.0                 0.0           NaN               NaN            NaN                NaN                NaN                    NaN               0.0                   0.0               0.0                   0.0                    NaN                        NaN                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "            pit_stops  11371        7     0.000000             NaN                 NaN           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               NaN                   NaN                    NaN                        NaN                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n",
            "            lap_times 589081        6     0.000000             NaN                 NaN           NaN               NaN            NaN                NaN                NaN                    NaN               NaN                   NaN               NaN                   NaN                    NaN                        NaN                NaN                    NaN                        NaN                            NaN                             NaN                                 NaN                           NaN                               NaN\n"
          ]
        }
      ],
      "source": [
        "# Parameterized completeness check function\n",
        "def check_completeness(df, name, key_cols=None):\n",
        "    \"\"\"Check completeness of a dataset. Returns summary dictionary.\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return {'name': name, 'status': 'empty', 'rows': 0}\n",
        "    \n",
        "    summary = {\n",
        "        'name': name,\n",
        "        'rows': len(df),\n",
        "        'columns': len(df.columns),\n",
        "        'missing_pct': df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100\n",
        "    }\n",
        "    \n",
        "    # Check key columns if provided\n",
        "    if key_cols:\n",
        "        missing_keys = []\n",
        "        for col in key_cols:\n",
        "            if col in df.columns:\n",
        "                missing_count = df[col].isnull().sum()\n",
        "                summary[f'{col}_missing'] = missing_count\n",
        "                summary[f'{col}_missing_pct'] = missing_count / len(df) * 100\n",
        "            else:\n",
        "                missing_keys.append(col)\n",
        "        if missing_keys:\n",
        "            summary['missing_key_cols'] = missing_keys\n",
        "    \n",
        "    return summary\n",
        "\n",
        "# Check completeness for all Kaggle datasets\n",
        "completeness_results = []\n",
        "for name, df in kaggle_data.items():\n",
        "    # Define key columns for each dataset\n",
        "    key_cols_map = {\n",
        "        'races': ['raceId', 'year', 'round', 'circuitId'],\n",
        "        'results': ['resultId', 'raceId', 'driverId', 'constructorId'],\n",
        "        'drivers': ['driverId'],\n",
        "        'constructors': ['constructorId'],\n",
        "        'circuits': ['circuitId'],\n",
        "        'qualifying': ['qualifyId', 'raceId', 'driverId'],\n",
        "        'driver_standings': ['driverStandingsId', 'raceId', 'driverId'],\n",
        "        'constructor_standings': ['constructorStandingsId', 'raceId', 'constructorId'],\n",
        "        'constructor_results': ['constructorResultsId', 'raceId', 'constructorId'],\n",
        "        'sprint_results': ['resultId', 'raceId', 'driverId']\n",
        "    }\n",
        "    key_cols = key_cols_map.get(name, [])\n",
        "    result = check_completeness(df, name, key_cols)\n",
        "    completeness_results.append(result)\n",
        "\n",
        "completeness_df = pd.DataFrame(completeness_results)\n",
        "print(\"Kaggle Data Completeness Summary:\")\n",
        "print(completeness_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Year Coverage (Kaggle):\n",
            "  Years: 1950 - 2024\n",
            "  Total races: 1125\n",
            "  Years >= 1994: 577 races\n",
            "\n",
            "Races per year (1994-2024):\n",
            "      num_races  round\n",
            "year                  \n",
            "1994         16     16\n",
            "1995         17     17\n",
            "1996         16     16\n",
            "1997         17     17\n",
            "1998         16     16\n",
            "1999         16     16\n",
            "2000         17     17\n",
            "2001         17     17\n",
            "2002         17     17\n",
            "2003         16     16\n",
            "2004         18     18\n",
            "2005         19     19\n",
            "2006         18     18\n",
            "2007         17     17\n",
            "2008         18     18\n",
            "2009         17     17\n",
            "2010         19     19\n",
            "2011         19     19\n",
            "2012         20     20\n",
            "2013         19     19\n",
            "2014         19     19\n",
            "2015         19     19\n",
            "2016         21     21\n",
            "2017         20     20\n",
            "2018         21     21\n",
            "2019         21     21\n",
            "2020         17     17\n",
            "2021         22     22\n",
            "2022         22     22\n",
            "2023         22     22\n",
            "2024         24     24\n",
            "\n",
            "No missing rounds detected (all rounds sequential)\n"
          ]
        }
      ],
      "source": [
        "# Year coverage check\n",
        "if 'races' in kaggle_data:\n",
        "    races = kaggle_data['races']\n",
        "    races['date'] = pd.to_datetime(races['date'], errors='coerce')\n",
        "    year_coverage = races.groupby('year').agg({\n",
        "        'raceId': 'count',\n",
        "        'round': 'max'\n",
        "    }).rename(columns={'raceId': 'num_races'})\n",
        "    \n",
        "    print(\"Year Coverage (Kaggle):\")\n",
        "    print(f\"  Years: {races['year'].min()} - {races['year'].max()}\")\n",
        "    print(f\"  Total races: {len(races)}\")\n",
        "    print(f\"  Years >= 1994: {len(races[races['year'] >= 1994])} races\")\n",
        "    print(f\"\\nRaces per year (1994-2024):\")\n",
        "    print(year_coverage[year_coverage.index >= 1994].to_string())\n",
        "    \n",
        "    # Check for missing rounds\n",
        "    missing_rounds = []\n",
        "    for year in range(1994, 2025):\n",
        "        year_races = races[races['year'] == year]\n",
        "        if len(year_races) > 0:\n",
        "            expected_rounds = set(range(1, year_races['round'].max() + 1))\n",
        "            actual_rounds = set(year_races['round'].unique())\n",
        "            missing = expected_rounds - actual_rounds\n",
        "            if missing:\n",
        "                missing_rounds.append({'year': year, 'missing_rounds': sorted(missing)})\n",
        "    \n",
        "    if missing_rounds:\n",
        "        print(f\"\\nMissing rounds detected: {missing_rounds}\")\n",
        "    else:\n",
        "        print(\"\\nNo missing rounds detected (all rounds sequential)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Driver Coverage:\n",
            "  Total drivers: 861\n",
            "  Missing forename: 0\n",
            "  Missing surname: 0\n",
            "  Missing nationality: 0\n",
            "\n",
            "Constructor Coverage:\n",
            "  Total constructors: 212\n",
            "  Missing name: 0\n",
            "  Missing nationality: 0\n",
            "\n",
            "FastF1 Coverage (2018-2024):\n",
            "  2018: RESULTS, LAPS (2/4)\n",
            "  2019: No data\n",
            "  2020: No data\n",
            "  2021: No data\n",
            "  2022: No data\n",
            "  2023: No data\n",
            "  2024: No data\n"
          ]
        }
      ],
      "source": [
        "# Driver and Constructor coverage\n",
        "if 'drivers' in kaggle_data:\n",
        "    drivers = kaggle_data['drivers']\n",
        "    print(f\"Driver Coverage:\")\n",
        "    print(f\"  Total drivers: {len(drivers)}\")\n",
        "    print(f\"  Missing forename: {drivers['forename'].isnull().sum()}\")\n",
        "    print(f\"  Missing surname: {drivers['surname'].isnull().sum()}\")\n",
        "    print(f\"  Missing nationality: {drivers['nationality'].isnull().sum()}\")\n",
        "\n",
        "if 'constructors' in kaggle_data:\n",
        "    constructors = kaggle_data['constructors']\n",
        "    print(f\"\\nConstructor Coverage:\")\n",
        "    print(f\"  Total constructors: {len(constructors)}\")\n",
        "    print(f\"  Missing name: {constructors['name'].isnull().sum()}\")\n",
        "    print(f\"  Missing nationality: {constructors['nationality'].isnull().sum()}\")\n",
        "# FastF1 coverage check\n",
        "print(f\"\\nFastF1 Coverage (2018-2024):\")\n",
        "for year in fastf1_years:\n",
        "    if year in fastf1_data:\n",
        "        datasets_present = list(fastf1_data[year].keys())\n",
        "        print(f\"  {year}: {', '.join(datasets_present)} ({len(datasets_present)}/4)\")\n",
        "    else:\n",
        "        print(f\"  {year}: No data\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Quality Checks\n",
        "\n",
        "Check missing values, outliers, data types, and range validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing Values Analysis (Top 10 columns per dataset):\n",
            "\n",
            "qualifying:\n",
            "q3    0.438346\n",
            "q2    0.209644\n"
          ]
        }
      ],
      "source": [
        "# Missing values analysis\n",
        "print(\"Missing Values Analysis (Top 10 columns per dataset):\")\n",
        "for name, df in kaggle_data.items():\n",
        "    if df is not None and not df.empty:\n",
        "        missing_pct = df.isnull().sum() / len(df) * 100\n",
        "        missing_pct = missing_pct[missing_pct > 0].sort_values(ascending=False)\n",
        "        if len(missing_pct) > 0:\n",
        "            print(f\"\\n{name}:\")\n",
        "            print(missing_pct.head(10).to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results Data Quality:\n",
            "  Position range: 1 - 39\n",
            "  Points range: 0.0 - 50.0\n",
            "  Laps range: 0 - 200\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'>' not supported between instances of 'str' and 'int'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Check for outliers\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mfastestLapSpeed\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results.columns:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     speed_outliers = results[\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfastestLapSpeed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m400\u001b[39;49m]  \u001b[38;5;66;03m# Unrealistic speeds\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(speed_outliers) > \u001b[32m0\u001b[39m:\n\u001b[32m     13\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Warning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(speed_outliers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows with speed > 400 km/h\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py:56\u001b[39m, in \u001b[36mOpsMixin.__gt__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__gt__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:6138\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6135\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6136\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6138\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m lvalues.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     res_values = \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:129\u001b[39m, in \u001b[36mcomp_method_OBJECT_ARRAY\u001b[39m\u001b[34m(op, x, y)\u001b[39m\n\u001b[32m    127\u001b[39m     result = libops.vec_compare(x.ravel(), y.ravel(), op)\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/ops.pyx:107\u001b[39m, in \u001b[36mpandas._libs.ops.scalar_compare\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mTypeError\u001b[39m: '>' not supported between instances of 'str' and 'int'"
          ]
        }
      ],
      "source": [
        "# Outlier detection for key numeric columns\n",
        "if 'results' in kaggle_data:\n",
        "    results = kaggle_data['results']\n",
        "    print(\"Results Data Quality:\")\n",
        "    print(f\"  Position range: {results['positionOrder'].min()} - {results['positionOrder'].max()}\")\n",
        "    print(f\"  Points range: {results['points'].min()} - {results['points'].max()}\")\n",
        "    print(f\"  Laps range: {results['laps'].min()} - {results['laps'].max()}\")\n",
        "    \n",
        "    # Check for outliers\n",
        "    if 'fastestLapSpeed' in results.columns:\n",
        "        speed_outliers = results[results['fastestLapSpeed'] > 400]  # Unrealistic speeds\n",
        "        if len(speed_outliers) > 0:\n",
        "            print(f\"  Warning: {len(speed_outliers)} rows with speed > 400 km/h\")\n",
        "    \n",
        "    # Check positionOrder consistency\n",
        "    position_issues = results[results['positionOrder'] <= 0]\n",
        "    if len(position_issues) > 0:\n",
        "        print(f\"  Warning: {len(position_issues)} rows with invalid positionOrder\")\n",
        "\n",
        "# Data type validation\n",
        "print(\"\\nData Type Validation:\")\n",
        "if 'races' in kaggle_data:\n",
        "    races = kaggle_data['races']\n",
        "    if 'date' in races.columns:\n",
        "        date_parsed = pd.to_datetime(races['date'], errors='coerce')\n",
        "        invalid_dates = date_parsed.isnull().sum() - races['date'].isnull().sum()\n",
        "        if invalid_dates > 0:\n",
        "            print(f\"  Warning: {invalid_dates} invalid dates in races.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Cross-Source Consistency (2018-2024)\n",
        "\n",
        "Compare Kaggle and FastF1 data for overlapping years to ensure consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Race matching between Kaggle and FastF1\n",
        "if 'races' in kaggle_data and 2018 in fastf1_data:\n",
        "    races = kaggle_data['races']\n",
        "    races_2018plus = races[races['year'] >= 2018].copy()\n",
        "    \n",
        "    # Normalize event names for matching\n",
        "    def normalize_event_name(name):\n",
        "        \"\"\"Normalize event name for matching.\"\"\"\n",
        "        if pd.isna(name):\n",
        "            return None\n",
        "        name = str(name).lower()\n",
        "        # Remove \"Grand Prix\" and common variations\n",
        "        name = name.replace('grand prix', '').strip()\n",
        "        name = name.replace('gp', '').strip()\n",
        "        return name\n",
        "    \n",
        "    races_2018plus['event_normalized'] = races_2018plus['name'].apply(normalize_event_name)\n",
        "    \n",
        "    # Get FastF1 event names\n",
        "    fastf1_events = set()\n",
        "    for year in range(2018, 2025):\n",
        "        if year in fastf1_data and 'RESULTS' in fastf1_data[year]:\n",
        "            events = fastf1_data[year]['RESULTS']['Event'].unique()\n",
        "            for event in events:\n",
        "                fastf1_events.add((year, normalize_event_name(event)))\n",
        "    \n",
        "    # Match races\n",
        "    matched = 0\n",
        "    unmatched = []\n",
        "    for _, race in races_2018plus.iterrows():\n",
        "        key = (race['year'], normalize_event_name(race['name']))\n",
        "        if key in fastf1_events:\n",
        "            matched += 1\n",
        "        else:\n",
        "            unmatched.append(race[['year', 'name', 'round']])\n",
        "    \n",
        "    print(f\"Race Matching (2018-2024):\")\n",
        "    print(f\"  Kaggle races: {len(races_2018plus)}\")\n",
        "    print(f\"  Matched to FastF1: {matched}\")\n",
        "    print(f\"  Unmatched: {len(unmatched)}\")\n",
        "    if unmatched:\n",
        "        print(f\"\\nUnmatched races:\")\n",
        "        print(pd.DataFrame(unmatched).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Result consistency check (compare finishing positions)\n",
        "if 'results' in kaggle_data and 2018 in fastf1_data:\n",
        "    results = kaggle_data['results']\n",
        "    races_2018 = results.merge(\n",
        "        kaggle_data['races'][['raceId', 'year', 'name']],\n",
        "        on='raceId',\n",
        "        how='left'\n",
        "    )\n",
        "    races_2018 = races_2018[races_2018['year'] >= 2018]\n",
        "    \n",
        "    # Sample check: Compare a few races\n",
        "    print(\"Result Consistency Check (Sample):\")\n",
        "    sample_races = races_2018['raceId'].unique()[:3]\n",
        "    \n",
        "    for race_id in sample_races:\n",
        "        race_info = races_2018[races_2018['raceId'] == race_id].iloc[0]\n",
        "        year = race_info['year']\n",
        "        event_name = race_info['name']\n",
        "        \n",
        "        # Get Kaggle results\n",
        "        kaggle_race_results = races_2018[races_2018['raceId'] == race_id].sort_values('positionOrder')\n",
        "        \n",
        "        # Get FastF1 results if available\n",
        "        if year in fastf1_data and 'RESULTS' in fastf1_data[year]:\n",
        "            fastf1_results = fastf1_data[year]['RESULTS']\n",
        "            fastf1_race = fastf1_results[\n",
        "                (fastf1_results['Year'] == year) & \n",
        "                (fastf1_results['Event'] == event_name) &\n",
        "                (fastf1_results['Session'] == 'R')\n",
        "            ]\n",
        "            \n",
        "            if len(fastf1_race) > 0:\n",
        "                print(f\"\\n  {year} {event_name}:\")\n",
        "                print(f\"    Kaggle: {len(kaggle_race_results)} drivers\")\n",
        "                print(f\"    FastF1: {len(fastf1_race)} drivers\")\n",
        "                # Note: Full driver matching would require driver name/ID mapping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Verification Report\n",
        "\n",
        "Generate summary report of all findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate verification report\n",
        "verification_report = {\n",
        "    'summary': {\n",
        "        'kaggle_datasets': len(kaggle_data),\n",
        "        'fastf1_years': len([y for y in fastf1_years if y in fastf1_data]),\n",
        "        'verification_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    },\n",
        "    'completeness': completeness_df.to_dict('records'),\n",
        "    'year_coverage': {\n",
        "        'min_year': kaggle_data['races']['year'].min() if 'races' in kaggle_data else None,\n",
        "        'max_year': kaggle_data['races']['year'].max() if 'races' in kaggle_data else None,\n",
        "        'races_1994plus': len(kaggle_data['races'][kaggle_data['races']['year'] >= 1994]) if 'races' in kaggle_data else None\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save report\n",
        "import json\n",
        "report_path = PROCESSED_ROOT / \"verification_report.json\"\n",
        "with open(report_path, 'w') as f:\n",
        "    json.dump(verification_report, f, indent=2, default=str)\n",
        "\n",
        "print(\"Verification Report Summary:\")\n",
        "print(f\"  Kaggle datasets: {verification_report['summary']['kaggle_datasets']}\")\n",
        "print(f\"  FastF1 years: {verification_report['summary']['fastf1_years']}\")\n",
        "print(f\"  Year range: {verification_report['year_coverage']['min_year']} - {verification_report['year_coverage']['max_year']}\")\n",
        "print(f\"  Races (1994+): {verification_report['year_coverage']['races_1994plus']}\")\n",
        "print(f\"\\nReport saved to: {report_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
