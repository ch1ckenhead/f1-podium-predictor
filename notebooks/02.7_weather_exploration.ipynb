{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02.7 - Weather Data Exploration\n",
        "\n",
        "This notebook explores the WEATHER data from FastF1, focusing on:\n",
        "- Understanding data structure and columns\n",
        "- Comparing datasets across years for consistency\n",
        "- Validating data completeness (events, sessions, coverage)\n",
        "- Identifying features for extraction\n",
        "- Checking year-over-year consistency in row counts, data quality, and coverage\n",
        "\n",
        "## Goals:\n",
        "- Understand the structure of WEATHER data\n",
        "- Identify available columns and data types\n",
        "- Compare row counts across years\n",
        "- Validate data completeness and consistency\n",
        "- Prepare for feature extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FastF1 data: C:\\Users\\erikv\\Downloads\\F1\\data\\raw\\fastf1_2018plus\n",
            "Python version: 3.12.9 (tags/v3.12.9:fdb8142, Feb  4 2025, 15:27:58) [MSC v.1942 64 bit (AMD64)]\n",
            "Pandas version: 2.3.3\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up paths\n",
        "PROJECT_ROOT = Path(r\"C:\\Users\\erikv\\Downloads\\F1\")\n",
        "FASTF1_ROOT = PROJECT_ROOT / \"data\" / \"raw\" / \"fastf1_2018plus\"\n",
        "\n",
        "print(f\"FastF1 data: {FASTF1_ROOT}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. File Size Analysis\n",
        "Check the size of all WEATHER files to understand data volume.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WEATHER File Sizes:\n",
            "============================================================\n",
            "ALL_WEATHER_2018.csv                 0.81 MB ( 0.001 GB)\n",
            "ALL_WEATHER_2019.csv                 0.67 MB ( 0.001 GB)\n",
            "ALL_WEATHER_2020.csv                 0.65 MB ( 0.001 GB)\n",
            "ALL_WEATHER_2021.csv                 0.89 MB ( 0.001 GB)\n",
            "ALL_WEATHER_2022.csv                 0.95 MB ( 0.001 GB)\n",
            "ALL_WEATHER_2023.csv                 0.89 MB ( 0.001 GB)\n",
            "ALL_WEATHER_2024.csv                 0.93 MB ( 0.001 GB)\n",
            "============================================================\n",
            "Total                                5.78 MB ( 0.006 GB)\n",
            "\n",
            "Number of files: 7\n"
          ]
        }
      ],
      "source": [
        "# Check file sizes for all weather files\n",
        "weather_files = sorted(FASTF1_ROOT.glob(\"ALL_WEATHER_*.csv\"))\n",
        "\n",
        "print(\"WEATHER File Sizes:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "total_size = 0\n",
        "file_sizes_by_year = {}\n",
        "for file_path in weather_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    size_mb = file_path.stat().st_size / (1024 * 1024)\n",
        "    size_gb = size_mb / 1024\n",
        "    total_size += size_mb\n",
        "    file_sizes_by_year[year] = size_mb\n",
        "    \n",
        "    print(f\"{file_path.name:30s} {size_mb:>10.2f} MB ({size_gb:>6.3f} GB)\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Total':30s} {total_size:>10.2f} MB ({total_size/1024:>6.3f} GB)\")\n",
        "print(f\"\\nNumber of files: {len(weather_files)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Column Discovery and Data Structure\n",
        "Explore the structure of weather data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing structure of: ALL_WEATHER_2018.csv\n",
            "============================================================\n",
            "\n",
            "Columns (11):\n",
            "   1. Time                           object            0.0% null\n",
            "   2. AirTemp                        float64           0.0% null\n",
            "   3. Humidity                       float64           0.0% null\n",
            "   4. Pressure                       float64           0.0% null\n",
            "   5. Rainfall                       bool              0.0% null\n",
            "   6. TrackTemp                      float64           0.0% null\n",
            "   7. WindDirection                  int64             0.0% null\n",
            "   8. WindSpeed                      float64           0.0% null\n",
            "   9. Year                           int64             0.0% null\n",
            "  10. Event                          object            0.0% null\n",
            "  11. Session                        object            0.0% null\n",
            "\n",
            "Data types:\n",
            "Time              object\n",
            "AirTemp          float64\n",
            "Humidity         float64\n",
            "Pressure         float64\n",
            "Rainfall            bool\n",
            "TrackTemp        float64\n",
            "WindDirection      int64\n",
            "WindSpeed        float64\n",
            "Year               int64\n",
            "Event             object\n",
            "Session           object\n",
            "dtype: object\n",
            "\n",
            "Memory usage: 0.02 MB (for 100 rows)\n",
            "\n",
            "Sample data (first 5 rows):\n",
            "                     Time  AirTemp  Humidity  Pressure  Rainfall  TrackTemp  \\\n",
            "0  0 days 00:00:57.060000     24.1      36.2     997.1     False       38.2   \n",
            "1  0 days 00:01:57.078000     24.0      36.3     997.1     False       38.6   \n",
            "2  0 days 00:02:57.090000     24.0      36.3     997.1     False       38.6   \n",
            "3  0 days 00:03:57.106000     23.9      37.2     997.0     False       38.7   \n",
            "4  0 days 00:04:57.121000     24.2      35.8     997.1     False       38.7   \n",
            "\n",
            "   WindDirection  WindSpeed  Year                  Event Session  \n",
            "0            294        3.0  2018  Australian Grand Prix       R  \n",
            "1            273        1.4  2018  Australian Grand Prix       R  \n",
            "2            273        1.4  2018  Australian Grand Prix       R  \n",
            "3            287        2.3  2018  Australian Grand Prix       R  \n",
            "4            309        3.5  2018  Australian Grand Prix       R  \n",
            "\n",
            "Data summary:\n",
            "                          Time     AirTemp    Humidity    Pressure Rainfall  \\\n",
            "count                      100  100.000000  100.000000  100.000000      100   \n",
            "unique                     100         NaN         NaN         NaN        1   \n",
            "top     0 days 00:00:57.060000         NaN         NaN         NaN    False   \n",
            "freq                         1         NaN         NaN         NaN      100   \n",
            "mean                       NaN   24.070000   30.956000  996.984000      NaN   \n",
            "std                        NaN    0.299663    4.278424    0.124495      NaN   \n",
            "min                        NaN   23.300000   25.600000  996.700000      NaN   \n",
            "25%                        NaN   23.900000   26.575000  996.900000      NaN   \n",
            "50%                        NaN   24.100000   28.900000  997.000000      NaN   \n",
            "75%                        NaN   24.200000   35.300000  997.100000      NaN   \n",
            "max                        NaN   24.800000   37.200000  997.200000      NaN   \n",
            "\n",
            "         TrackTemp  WindDirection   WindSpeed    Year                  Event  \\\n",
            "count   100.000000     100.000000  100.000000   100.0                    100   \n",
            "unique         NaN            NaN         NaN     NaN                      1   \n",
            "top            NaN            NaN         NaN     NaN  Australian Grand Prix   \n",
            "freq           NaN            NaN         NaN     NaN                    100   \n",
            "mean     36.734000     293.970000    3.579000  2018.0                    NaN   \n",
            "std       1.714184      36.948081    1.193187     0.0                    NaN   \n",
            "min      33.000000       0.000000    0.900000  2018.0                    NaN   \n",
            "25%      36.275000     288.500000    2.875000  2018.0                    NaN   \n",
            "50%      37.100000     295.000000    3.600000  2018.0                    NaN   \n",
            "75%      38.200000     309.000000    4.300000  2018.0                    NaN   \n",
            "max      38.900000     354.000000    6.600000  2018.0                    NaN   \n",
            "\n",
            "       Session  \n",
            "count      100  \n",
            "unique       1  \n",
            "top          R  \n",
            "freq       100  \n",
            "mean       NaN  \n",
            "std        NaN  \n",
            "min        NaN  \n",
            "25%        NaN  \n",
            "50%        NaN  \n",
            "75%        NaN  \n",
            "max        NaN  \n"
          ]
        }
      ],
      "source": [
        "# Load a sample from first file to understand structure\n",
        "test_file = weather_files[0] if weather_files else None\n",
        "\n",
        "if test_file:\n",
        "    print(f\"Analyzing structure of: {test_file.name}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Read first few rows\n",
        "    sample_df = pd.read_csv(test_file, nrows=100)\n",
        "    \n",
        "    print(f\"\\nColumns ({len(sample_df.columns)}):\")\n",
        "    for i, col in enumerate(sample_df.columns, 1):\n",
        "        dtype = sample_df[col].dtype\n",
        "        null_pct = (sample_df[col].isnull().sum() / len(sample_df)) * 100\n",
        "        print(f\"  {i:2d}. {col:30s} {str(dtype):15s} {null_pct:5.1f}% null\")\n",
        "    \n",
        "    print(f\"\\nData types:\")\n",
        "    print(sample_df.dtypes)\n",
        "    \n",
        "    print(f\"\\nMemory usage: {sample_df.memory_usage(deep=True).sum() / (1024 * 1024):.2f} MB (for 100 rows)\")\n",
        "    \n",
        "    print(f\"\\nSample data (first 5 rows):\")\n",
        "    print(sample_df.head())\n",
        "    \n",
        "    print(f\"\\nData summary:\")\n",
        "    print(sample_df.describe(include='all'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Row Count Comparison Across Years\n",
        "Compare row counts for all weather files across different years to understand data volume trends and consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row Count Comparison by Year:\n",
            "======================================================================\n",
            "\n",
            "2018: ALL_WEATHER_2018.csv\n",
            "  File size: 0.81 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 9,707\n",
            "  ✓ Rows per MB: 11,995\n",
            "\n",
            "2019: ALL_WEATHER_2019.csv\n",
            "  File size: 0.67 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 8,077\n",
            "  ✓ Rows per MB: 12,075\n",
            "\n",
            "2020: ALL_WEATHER_2020.csv\n",
            "  File size: 0.65 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 7,822\n",
            "  ✓ Rows per MB: 12,043\n",
            "\n",
            "2021: ALL_WEATHER_2021.csv\n",
            "  File size: 0.89 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 10,616\n",
            "  ✓ Rows per MB: 11,969\n",
            "\n",
            "2022: ALL_WEATHER_2022.csv\n",
            "  File size: 0.95 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 11,285\n",
            "  ✓ Rows per MB: 11,937\n",
            "\n",
            "2023: ALL_WEATHER_2023.csv\n",
            "  File size: 0.89 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 10,613\n",
            "  ✓ Rows per MB: 11,953\n",
            "\n",
            "2024: ALL_WEATHER_2024.csv\n",
            "  File size: 0.93 MB\n",
            "  Counting rows...\n",
            "  ✓ Total rows: 11,127\n",
            "  ✓ Rows per MB: 11,926\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - Row Counts by Year:\n",
            "======================================================================\n",
            "\n",
            "Year           Row Count     File Size (MB)      Rows/MB   % of Total\n",
            "----------------------------------------------------------------------\n",
            "2018               9,707               0.81       11,995       14.02%\n",
            "2019               8,077               0.67       12,075       11.66%\n",
            "2020               7,822               0.65       12,043       11.30%\n",
            "2021              10,616               0.89       11,969       15.33%\n",
            "2022              11,285               0.95       11,937       16.30%\n",
            "2023              10,613               0.89       11,953       15.33%\n",
            "2024              11,127               0.93       11,926       16.07%\n",
            "----------------------------------------------------------------------\n",
            "TOTAL             69,247               5.78       11,978       100.00%\n",
            "\n",
            "Maximum rows: 2022 with 11,285 rows\n",
            "Minimum rows: 2020 with 7,822 rows\n",
            "Range: 3,463 rows (44.3% difference)\n",
            "\n",
            "Consistency check:\n",
            "  Median rows: 10,613\n",
            "  Standard deviation: 1,421\n",
            "  Coefficient of variation: 13.4%\n",
            "  ✓ Low variation - data appears consistent across years\n"
          ]
        }
      ],
      "source": [
        "# Count rows for all weather files\n",
        "print(\"Row Count Comparison by Year:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "row_counts_by_year = {}\n",
        "\n",
        "for file_path in weather_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    file_size_mb = file_sizes_by_year[year]\n",
        "    \n",
        "    print(f\"\\n{year}: {file_path.name}\")\n",
        "    print(f\"  File size: {file_size_mb:.2f} MB\")\n",
        "    print(f\"  Counting rows...\")\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        row_count = len(df)\n",
        "        row_counts_by_year[year] = row_count\n",
        "        \n",
        "        print(f\"  ✓ Total rows: {row_count:,}\")\n",
        "        \n",
        "        # Calculate rows per MB\n",
        "        rows_per_mb = row_count / file_size_mb if file_size_mb > 0 else 0\n",
        "        print(f\"  ✓ Rows per MB: {rows_per_mb:,.0f}\")\n",
        "        \n",
        "        # Clear from memory\n",
        "        del df\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SUMMARY - Row Counts by Year:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create comparison DataFrame\n",
        "if row_counts_by_year:\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Year': list(row_counts_by_year.keys()),\n",
        "        'Row_Count': list(row_counts_by_year.values()),\n",
        "        'File_Size_MB': [file_sizes_by_year.get(year, 0) for year in row_counts_by_year.keys()]\n",
        "    })\n",
        "    \n",
        "    # Sort by year\n",
        "    comparison_df = comparison_df.sort_values('Year')\n",
        "    \n",
        "    # Calculate additional metrics\n",
        "    comparison_df['Rows_Per_MB'] = comparison_df['Row_Count'] / comparison_df['File_Size_MB']\n",
        "    comparison_df['Pct_of_Total'] = (comparison_df['Row_Count'] / comparison_df['Row_Count'].sum() * 100).round(2)\n",
        "    \n",
        "    # Display formatted table\n",
        "    print(f\"\\n{'Year':<8} {'Row Count':>15} {'File Size (MB)':>18} {'Rows/MB':>12} {'% of Total':>12}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    for _, row in comparison_df.iterrows():\n",
        "        print(f\"{row['Year']:<8} {row['Row_Count']:>15,} {row['File_Size_MB']:>18,.2f} \"\n",
        "              f\"{row['Rows_Per_MB']:>12,.0f} {row['Pct_of_Total']:>11.2f}%\")\n",
        "    \n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'TOTAL':<8} {comparison_df['Row_Count'].sum():>15,} {comparison_df['File_Size_MB'].sum():>18,.2f} \"\n",
        "          f\"{comparison_df['Row_Count'].sum() / comparison_df['File_Size_MB'].sum():>12,.0f} {'100.00':>12}%\")\n",
        "    \n",
        "    # Find min/max\n",
        "    max_year = comparison_df.loc[comparison_df['Row_Count'].idxmax(), 'Year']\n",
        "    max_rows = comparison_df['Row_Count'].max()\n",
        "    min_year = comparison_df.loc[comparison_df['Row_Count'].idxmin(), 'Year']\n",
        "    min_rows = comparison_df['Row_Count'].min()\n",
        "    \n",
        "    print(f\"\\nMaximum rows: {max_year} with {max_rows:,} rows\")\n",
        "    print(f\"Minimum rows: {min_year} with {min_rows:,} rows\")\n",
        "    print(f\"Range: {max_rows - min_rows:,} rows ({((max_rows / min_rows - 1) * 100):.1f}% difference)\")\n",
        "    \n",
        "    # Check for consistency\n",
        "    median_rows = comparison_df['Row_Count'].median()\n",
        "    std_rows = comparison_df['Row_Count'].std()\n",
        "    cv = (std_rows / median_rows * 100) if median_rows > 0 else 0\n",
        "    \n",
        "    print(f\"\\nConsistency check:\")\n",
        "    print(f\"  Median rows: {median_rows:,.0f}\")\n",
        "    print(f\"  Standard deviation: {std_rows:,.0f}\")\n",
        "    print(f\"  Coefficient of variation: {cv:.1f}%\")\n",
        "    \n",
        "    if cv > 30:\n",
        "        print(f\"  ⚠️  High variation detected - may indicate data completeness issues\")\n",
        "    elif cv > 15:\n",
        "        print(f\"  ⚠️  Moderate variation - check for missing events or sessions\")\n",
        "    else:\n",
        "        print(f\"  ✓ Low variation - data appears consistent across years\")\n",
        "    \n",
        "    # Store for later use\n",
        "    weather_row_counts = comparison_df\n",
        "else:\n",
        "    print(\"No row counts available\")\n",
        "    weather_row_counts = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Completeness Validation:\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'weather_files' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Extract unique events and sessions from weather data\u001b[39;00m\n\u001b[32m     19\u001b[39m weather_coverage = {}\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mweather_files\u001b[49m:\n\u001b[32m     22\u001b[39m     year = file_path.stem.split(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m]\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Analyzing coverage...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'weather_files' is not defined"
          ]
        }
      ],
      "source": [
        "# Expected races per year (from known F1 calendar)\n",
        "expected_races = {\n",
        "    '2018': 21,\n",
        "    '2019': 21,\n",
        "    '2020': 17,  # COVID-19 shortened season\n",
        "    '2021': 22,\n",
        "    '2022': 22,\n",
        "    '2023': 22,\n",
        "    '2024': 24\n",
        "}\n",
        "\n",
        "# Expected sessions per race (typically: FP1, FP2, FP3, Q, R)\n",
        "expected_sessions_per_race = 5\n",
        "\n",
        "print(\"Data Completeness Validation:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Extract unique events and sessions from weather data\n",
        "weather_coverage = {}\n",
        "\n",
        "for file_path in weather_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    print(f\"\\n{year}: Analyzing coverage...\")\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        unique_events = df['Event'].unique() if 'Event' in df.columns else []\n",
        "        unique_sessions = df['Session'].unique() if 'Session' in df.columns else []\n",
        "        \n",
        "        # Count unique event-session combinations\n",
        "        if 'Event' in df.columns and 'Session' in df.columns:\n",
        "            event_session_counts = df.groupby(['Event', 'Session']).size()\n",
        "            unique_combinations = len(event_session_counts)\n",
        "        else:\n",
        "            unique_combinations = 0\n",
        "        \n",
        "        weather_coverage[year] = {\n",
        "            'unique_events': len(unique_events),\n",
        "            'unique_sessions': len(unique_sessions),\n",
        "            'events': sorted(unique_events),\n",
        "            'sessions': sorted(unique_sessions),\n",
        "            'event_session_combinations': unique_combinations,\n",
        "            'total_rows': len(df)\n",
        "        }\n",
        "        \n",
        "        print(f\"  Found {len(unique_events)} unique events\")\n",
        "        print(f\"  Found {len(unique_sessions)} unique sessions: {sorted(unique_sessions)}\")\n",
        "        print(f\"  Found {unique_combinations} unique event-session combinations\")\n",
        "        print(f\"  Total rows: {len(df):,}\")\n",
        "        \n",
        "        # Clear from memory\n",
        "        del df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "        weather_coverage[year] = None\n",
        "\n",
        "# Validation: Compare against expected\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPLETENESS CHECK:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n{'Year':<8} {'Expected Races':>15} {'Found Events':>15} {'Difference':>12} {'Status':>15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "completeness_issues = []\n",
        "\n",
        "for year in sorted(weather_coverage.keys()):\n",
        "    if weather_coverage[year] is None:\n",
        "        continue\n",
        "    \n",
        "    found_events = weather_coverage[year]['unique_events']\n",
        "    expected = expected_races.get(year, 0)\n",
        "    diff = found_events - expected\n",
        "    \n",
        "    if expected > 0:\n",
        "        if diff == 0:\n",
        "            status = \"✓ Complete\"\n",
        "        elif diff < 0:\n",
        "            status = f\"⚠ Missing {abs(diff)}\"\n",
        "            completeness_issues.append({\n",
        "                'year': year,\n",
        "                'issue': f\"Missing {abs(diff)} race(s). Expected {expected}, found {found_events}\"\n",
        "            })\n",
        "        else:\n",
        "            status = f\"+{diff} extra\"\n",
        "    else:\n",
        "        status = \"? Unknown\"\n",
        "    \n",
        "    print(f\"{year:<8} {expected:>15} {found_events:>15} {diff:>+12} {status:>15}\")\n",
        "\n",
        "# Calculate rows per race (normalized)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ROWS PER RACE (Normalized for comparison):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n{'Year':<8} {'Total Rows':>15} {'Events Found':>15} {'Rows/Race':>15} {'Relative':>12}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "rows_per_race_by_year = {}\n",
        "\n",
        "for year in sorted(weather_coverage.keys()):\n",
        "    if weather_coverage[year] is None:\n",
        "        continue\n",
        "    \n",
        "    total_rows = weather_coverage[year]['total_rows']\n",
        "    events = weather_coverage[year]['unique_events']\n",
        "    \n",
        "    if events > 0:\n",
        "        rows_per_race = total_rows / events\n",
        "        rows_per_race_by_year[year] = rows_per_race\n",
        "        \n",
        "        # Calculate relative to median for comparison\n",
        "        if len(rows_per_race_by_year) > 1:\n",
        "            median_rpr = np.median(list(rows_per_race_by_year.values()))\n",
        "            relative = (rows_per_race / median_rpr * 100) if median_rpr > 0 else 100\n",
        "        else:\n",
        "            relative = 100\n",
        "        \n",
        "        print(f\"{year:<8} {total_rows:>15,} {events:>15} {rows_per_race:>15,.0f} {relative:>11.0f}%\")\n",
        "\n",
        "# Flag significant variations\n",
        "if len(rows_per_race_by_year) > 1:\n",
        "    median_rpr = np.median(list(rows_per_race_by_year.values()))\n",
        "    std_rpr = np.std(list(rows_per_race_by_year.values()))\n",
        "    \n",
        "    print(\"\\n⚠️  VARIATION ANALYSIS:\")\n",
        "    for year in sorted(rows_per_race_by_year.keys()):\n",
        "        rpr = rows_per_race_by_year[year]\n",
        "        deviation = abs(rpr - median_rpr) / median_rpr * 100 if median_rpr > 0 else 0\n",
        "        \n",
        "        if deviation > 30:  # More than 30% deviation\n",
        "            print(f\"  {year}: {deviation:.1f}% deviation from median ({median_rpr:.0f} rows/race)\")\n",
        "            print(f\"    Possible causes: Different sampling frequency, missing sessions, or data quality issues\")\n",
        "        elif deviation > 15:\n",
        "            print(f\"  {year}: {deviation:.1f}% deviation (moderate - may be normal variation)\")\n",
        "\n",
        "# Summary of issues\n",
        "if completeness_issues:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"⚠️  DATA COMPLETENESS ISSUES DETECTED:\")\n",
        "    print(\"=\" * 80)\n",
        "    for issue in completeness_issues:\n",
        "        print(f\"  {issue['year']}: {issue['issue']}\")\n",
        "else:\n",
        "    print(\"\\n✅ No major completeness issues detected in event coverage.\")\n",
        "    print(\"   Row count variations likely due to:\")\n",
        "    print(\"   - Different number of races per year (normal)\")\n",
        "    print(\"   - Different session lengths (normal)\")\n",
        "    print(\"   - Different weather sampling frequencies (possible)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze weather features across years\n",
        "print(\"Weather Feature Analysis:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Sample from each year to check feature consistency\n",
        "feature_summary = {}\n",
        "\n",
        "for file_path in weather_files:\n",
        "    year = file_path.stem.split('_')[-1]\n",
        "    print(f\"\\n{year}: Analyzing features...\")\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        \n",
        "        # Numeric columns summary\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        \n",
        "        # Exclude Year if it's numeric\n",
        "        if 'Year' in numeric_cols:\n",
        "            numeric_cols.remove('Year')\n",
        "        \n",
        "        feature_summary[year] = {}\n",
        "        \n",
        "        print(f\"  Numeric features: {numeric_cols}\")\n",
        "        \n",
        "        for col in numeric_cols:\n",
        "            if col in df.columns:\n",
        "                feature_summary[year][col] = {\n",
        "                    'mean': df[col].mean(),\n",
        "                    'std': df[col].std(),\n",
        "                    'min': df[col].min(),\n",
        "                    'max': df[col].max(),\n",
        "                    'null_pct': (df[col].isnull().sum() / len(df)) * 100\n",
        "                }\n",
        "                print(f\"    {col}: mean={df[col].mean():.2f}, std={df[col].std():.2f}, \"\n",
        "                      f\"range=[{df[col].min():.2f}, {df[col].max():.2f}], \"\n",
        "                      f\"null={feature_summary[year][col]['null_pct']:.1f}%\")\n",
        "        \n",
        "        # Categorical columns\n",
        "        categorical_cols = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
        "        if 'Year' in categorical_cols:\n",
        "            categorical_cols.remove('Year')\n",
        "        if 'Event' in categorical_cols:\n",
        "            categorical_cols.remove('Event')\n",
        "        if 'Session' in categorical_cols:\n",
        "            categorical_cols.remove('Session')\n",
        "        \n",
        "        print(f\"  Categorical features: {categorical_cols}\")\n",
        "        for col in categorical_cols:\n",
        "            if col in df.columns:\n",
        "                unique_count = df[col].nunique()\n",
        "                print(f\"    {col}: {unique_count} unique values\")\n",
        "        \n",
        "        del df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  Error: {e}\")\n",
        "\n",
        "# Cross-year consistency check\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CROSS-YEAR CONSISTENCY CHECK:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if feature_summary:\n",
        "    # Check if all years have same features\n",
        "    all_features = set()\n",
        "    for year_data in feature_summary.values():\n",
        "        all_features.update(year_data.keys())\n",
        "    \n",
        "    print(f\"\\nAll numeric features found: {sorted(all_features)}\")\n",
        "    \n",
        "    # Check consistency of feature ranges\n",
        "    print(\"\\nFeature range consistency:\")\n",
        "    for feature in sorted(all_features):\n",
        "        print(f\"\\n  {feature}:\")\n",
        "        years_with_feature = [y for y in feature_summary.keys() if feature in feature_summary[y]]\n",
        "        \n",
        "        if len(years_with_feature) < len(feature_summary):\n",
        "            missing_years = set(feature_summary.keys()) - set(years_with_feature)\n",
        "            print(f\"    ⚠️  Missing in years: {sorted(missing_years)}\")\n",
        "        else:\n",
        "            means = [feature_summary[y][feature]['mean'] for y in years_with_feature]\n",
        "            stds = [feature_summary[y][feature]['std'] for y in years_with_feature]\n",
        "            \n",
        "            mean_of_means = np.mean(means)\n",
        "            std_of_means = np.std(means)\n",
        "            \n",
        "            print(f\"    Mean across years: {mean_of_means:.2f} (std: {std_of_means:.2f})\")\n",
        "            \n",
        "            if std_of_means / mean_of_means > 0.5:  # High variation\n",
        "                print(f\"    ⚠️  High variation in means across years\")\n",
        "            \n",
        "            # Check for outliers\n",
        "            for year in years_with_feature:\n",
        "                year_mean = feature_summary[year][feature]['mean']\n",
        "                z_score = abs(year_mean - mean_of_means) / std_of_means if std_of_means > 0 else 0\n",
        "                if z_score > 2:\n",
        "                    print(f\"    ⚠️  {year}: Outlier (z-score: {z_score:.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualization (Optional)\n",
        "Visualize row counts and data distribution if matplotlib is available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Visualize row counts comparison (if matplotlib is available)\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    if weather_row_counts is not None:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "        \n",
        "        # Plot 1: Row counts by year\n",
        "        ax1.bar(weather_row_counts['Year'].astype(str), weather_row_counts['Row_Count'], \n",
        "                color='steelblue', alpha=0.7)\n",
        "        ax1.set_xlabel('Year', fontsize=12)\n",
        "        ax1.set_ylabel('Row Count', fontsize=12)\n",
        "        ax1.set_title('Weather Row Counts by Year', fontsize=14, fontweight='bold')\n",
        "        ax1.grid(axis='y', alpha=0.3)\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for idx, row in weather_row_counts.iterrows():\n",
        "            height = row['Row_Count']\n",
        "            ax1.text(row['Year'], height, f'{height:,.0f}', \n",
        "                    ha='center', va='bottom', fontsize=9, rotation=90)\n",
        "        \n",
        "        # Plot 2: Rows per race (normalized)\n",
        "        if rows_per_race_by_year:\n",
        "            years = sorted(rows_per_race_by_year.keys())\n",
        "            rpr_values = [rows_per_race_by_year[y] for y in years]\n",
        "            \n",
        "            ax2.bar([str(y) for y in years], rpr_values, color='coral', alpha=0.7)\n",
        "            ax2.set_xlabel('Year', fontsize=12)\n",
        "            ax2.set_ylabel('Rows per Race', fontsize=12)\n",
        "            ax2.set_title('Normalized Rows per Race', fontsize=14, fontweight='bold')\n",
        "            ax2.grid(axis='y', alpha=0.3)\n",
        "            \n",
        "            # Add value labels\n",
        "            for year, value in zip(years, rpr_values):\n",
        "                ax2.text(str(year), value, f'{value:,.0f}', \n",
        "                        ha='center', va='bottom', fontsize=9)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"Visualization created successfully!\")\n",
        "    else:\n",
        "        print(\"No data available for visualization\")\n",
        "        \n",
        "except ImportError:\n",
        "    print(\"Matplotlib not available - skipping visualization\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating visualization: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary and Feature Extraction Recommendations\n",
        "Summarize findings and recommend features for extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"WEATHER DATA SUMMARY AND RECOMMENDATIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. AVAILABLE FEATURES:\")\n",
        "print(\"-\" * 80)\n",
        "if test_file:\n",
        "    sample = pd.read_csv(test_file, nrows=1)\n",
        "    print(\"Columns available:\")\n",
        "    for col in sample.columns:\n",
        "        print(f\"  - {col}\")\n",
        "\n",
        "print(\"\\n2. POTENTIAL FEATURES FOR EXTRACTION:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"Based on analysis, recommended features:\")\n",
        "print(\"  - Time-based: Time, SessionTime\")\n",
        "print(\"  - Temperature: AirTemp, TrackTemp\")\n",
        "print(\"  - Atmospheric: Humidity, Pressure, WindDirection, WindSpeed\")\n",
        "print(\"  - Conditions: Rainfall (boolean)\")\n",
        "print(\"  - Context: Year, Event, Session\")\n",
        "print(\"  - Derived: Temperature delta (TrackTemp - AirTemp), Wind components\")\n",
        "\n",
        "print(\"\\n3. DATA QUALITY:\")\n",
        "print(\"-\" * 80)\n",
        "if completeness_issues:\n",
        "    print(\"  ⚠️  Issues found - review completeness section above\")\n",
        "else:\n",
        "    print(\"  ✓ No major data quality issues detected\")\n",
        "\n",
        "if weather_row_counts is not None:\n",
        "    cv = (weather_row_counts['Row_Count'].std() / weather_row_counts['Row_Count'].mean() * 100)\n",
        "    print(f\"  Consistency (CV): {cv:.1f}%\")\n",
        "    if cv > 30:\n",
        "        print(\"  ⚠️  High variation - investigate specific years\")\n",
        "\n",
        "print(\"\\n4. FEATURE EXTRACTION STRATEGY:\")\n",
        "print(\"-\" * 80)\n",
        "print(\"  - Group by: Year, Event, Session\")\n",
        "print(\"  - Aggregate: Mean, Min, Max, Std for numeric features\")\n",
        "print(\"  - Flag conditions: Rain events, extreme temperatures\")\n",
        "print(\"  - Time features: Session start/end conditions\")\n",
        "print(\"  - Join key: Year + Event + Session (matches LAPS and TELEMETRY)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
